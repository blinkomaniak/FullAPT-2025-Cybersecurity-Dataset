{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Elasticsearch Index Downloader\n",
    "\n",
    "## üìñ Overview\n",
    "\n",
    "This notebook extracts cybersecurity data from an Elasticsearch cluster containing Windows event logs and network traffic. It provides an interactive interface for users to select specific indices and time ranges for data extraction.\n",
    "\n",
    "### üéØ Purpose\n",
    "\n",
    "- **Connect** to Elasticsearch cluster securely\n",
    "- **Discover** available indices containing security data  \n",
    "- **Select** relevant indices through user interaction\n",
    "- **Extract** data within specified time ranges\n",
    "- **Output** structured JSONL files for further processing\n",
    "\n",
    "### üìä Target Data Types\n",
    "\n",
    "- **Windows Sysmon Events**: Process creation, network connections, file operations\n",
    "- **Network Traffic**: DNS queries, HTTP requests, TLS handshakes, flow data\n",
    "\n",
    "--- -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Required Libraries\n",
    "\n",
    "Import essential libraries for Elasticsearch integration and data processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration Parameters\n",
    "\n",
    "Set up connection details and extraction settings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Connection Functions\n",
    "\n",
    "Functions to establish and validate Elasticsearch connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for Elasticsearch integration and data handling\n",
    "from elasticsearch import Elasticsearch          # Elasticsearch client for cluster communication\n",
    "from elasticsearch.helpers import scan           # Efficient scrolling through large result sets\n",
    "from datetime import datetime, timezone          # Timestamp parsing and timezone handling\n",
    "import json                                      # JSON serialization for JSONL output format\n",
    "import os                                        # File system operations for output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Index Discovery Functions\n",
    "\n",
    "Functions to find and filter relevant security indices in the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearch cluster connection configuration\n",
    "es_host = \"https://10.2.0.20:9200\"               # HTTPS endpoint for secure connection\n",
    "username = \"elastic\"                             # Authentication username\n",
    "password = \"hiYqiU21LVg0F8krD=XN\"               # Authentication password\n",
    "\n",
    "# Data discovery and filtering settings  \n",
    "keywords = ['sysmon', 'network_traffic']         # Keywords to identify relevant security indices\n",
    "output_dir = \"./\"                                # Local directory for extracted JSONL files\n",
    "\n",
    "# Time format for user input (human-readable format)\n",
    "TIMESTAMP_FORMAT = \"%b %d, %Y @ %H:%M:%S.%f\"     # Example: \"Jan 29, 2025 @ 04:24:54.863\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÖ Temporal Processing & Data Extraction\n",
    "\n",
    "### ‚è∞ Time Range Management\n",
    "\n",
    "The temporal processing system handles time-based filtering for cybersecurity event extraction. This is critical for focusing on specific attack simulation windows or investigation timeframes.\n",
    "\n",
    "#### Time Format Design\n",
    "- **Human-Readable Input**: Format like `'Jan 29, 2025 @ 04:24:54.863'` for intuitive user interaction\n",
    "- **UTC Standardization**: All timestamps converted to UTC for consistent processing\n",
    "- **Precision Support**: Microsecond precision for high-resolution security event correlation\n",
    "- **Timezone Handling**: Automatic UTC conversion regardless of input timezone indicators\n",
    "\n",
    "#### Data Extraction Architecture\n",
    "The extraction system implements **streaming processing** for memory-efficient handling of large security datasets:\n",
    "\n",
    "##### Extraction Features\n",
    "- **Time-Range Queries**: Elasticsearch range queries on `@timestamp` field\n",
    "- **Streaming Output**: Direct write to JSONL files without loading entire datasets in memory\n",
    "- **Progress Tracking**: Real-time document count reporting during extraction\n",
    "- **Error Resilience**: Individual index failures don't stop the entire process\n",
    "\n",
    "##### JSONL Format Benefits\n",
    "- **Line-by-Line Processing**: Each security event on a separate line for easy streaming\n",
    "- **Fault Tolerance**: Partial files remain valid if extraction is interrupted\n",
    "- **ML Pipeline Ready**: Direct compatibility with pandas, ML frameworks, and data processing tools\n",
    "- **Human Readable**: JSON format allows manual inspection and debugging\n",
    "\n",
    "#### Processing Functions\n",
    "\n",
    "1. **`parse_utc_time(time_str)`**: Converts human-readable timestamps to UTC datetime objects\n",
    "2. **`export_index_data(es, index_name, start_time, end_time)`**: Streams security events to JSONL files\n",
    "\n",
    "This design prioritizes **usability** for researchers while maintaining **efficiency** for large-scale cybersecurity data processing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_elasticsearch():\n",
    "    \"\"\"\n",
    "    Create secure connection to Elasticsearch cluster.\n",
    "    \n",
    "    Returns:\n",
    "        Elasticsearch: Configured client instance with authentication\n",
    "    \"\"\"\n",
    "    return Elasticsearch(\n",
    "        hosts=[es_host],                         # Cluster endpoint\n",
    "        basic_auth=(username, password),         # Username/password authentication  \n",
    "        verify_certs=False,                      # Disable SSL cert verification (lab environment)\n",
    "        ssl_show_warn=False                      # Suppress SSL warnings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_connection(es):\n",
    "    \"\"\"\n",
    "    Validate Elasticsearch connection with ping test.\n",
    "    \n",
    "    Args:\n",
    "        es (Elasticsearch): Elasticsearch client instance\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if connection successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return es.ping()                         # Test basic connectivity\n",
    "    except Exception as e:\n",
    "        print(f\"üî• Connection failed: {e}\")      # Display connection error\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Main Orchestration Function\n",
    "\n",
    "Main function that coordinates the entire data extraction workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_relevant_indices(es, keywords):\n",
    "    \"\"\"\n",
    "    Discover indices containing security-related keywords.\n",
    "    \n",
    "    Args:\n",
    "        es (Elasticsearch): Elasticsearch client instance\n",
    "        keywords (list): Keywords to filter indices (e.g., ['sysmon', 'network_traffic'])\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing index metadata (name, size, creation date)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Query cluster for all indices with metadata\n",
    "        response = es.cat.indices(format=\"json\", h=\"index,store.size,creation.date\")\n",
    "        \n",
    "        # Filter indices containing security keywords and extract metadata\n",
    "        return [\n",
    "            {\n",
    "                \"name\": idx[\"index\"],                                                    # Index name\n",
    "                \"size\": idx.get(\"store.size\", \"0b\"),                                   # Storage size\n",
    "                \"created\": datetime.fromtimestamp(int(idx[\"creation.date\"])/1000, tz=timezone.utc)  # Creation timestamp\n",
    "            }\n",
    "            for idx in response\n",
    "            if any(kw in idx[\"index\"] for kw in keywords)                              # Filter by keywords\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"üö® Error listing indices: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Usage Summary\n",
    "\n",
    "### üéØ What This Notebook Does\n",
    "\n",
    "1. **Connects** to Elasticsearch cluster using configured credentials\n",
    "2. **Discovers** indices containing 'sysmon' or 'network_traffic' data\n",
    "3. **Presents** available indices with size and creation date information\n",
    "4. **Allows** interactive selection of specific indices to process\n",
    "5. **Accepts** human-readable time range input for data filtering\n",
    "6. **Extracts** matching documents and saves as JSONL files\n",
    "\n",
    "### üìä Output Files\n",
    "\n",
    "- **Format**: JSONL (JSON Lines) - one JSON object per line\n",
    "- **Naming**: Index name with special characters replaced (`:` ‚Üí `_`, `.` ‚Üí `-`)\n",
    "- **Content**: Raw document sources from Elasticsearch (`_source` field)\n",
    "- **Location**: Current directory (`./`)\n",
    "\n",
    "### üîß Configuration Notes\n",
    "\n",
    "- **SSL Verification**: Disabled for lab environments\n",
    "- **Authentication**: Basic username/password\n",
    "- **Time Format**: `\"Jan 29, 2025 @ 04:24:54.863\"` (microsecond precision)\n",
    "- **Keywords**: Filters for `sysmon` and `network_traffic` indices only\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def display_indices_selector(indices):\n",
    "    \"\"\"\n",
    "    Interactive interface for user to select which indices to process.\n",
    "    \n",
    "    Args:\n",
    "        indices (list): List of index dictionaries from list_relevant_indices()\n",
    "        \n",
    "    Returns:\n",
    "        list: List of selected index names, empty list if user exits\n",
    "    \"\"\"\n",
    "    # Display available indices with metadata\n",
    "    print(f\"\\nüìÇ Found {len(indices)} relevant indices:\")\n",
    "    for i, idx in enumerate(indices, 1):\n",
    "        print(f\"{i:>3}. {idx['name']} ({idx['size']}) [Created: {idx['created'].strftime('%Y-%m-%d')}]\")\n",
    "\n",
    "    # Interactive selection loop\n",
    "    while True:\n",
    "        selection = input(\"\\nüî¢ Select indices (comma-separated numbers, 'all', or 'exit'): \").strip().lower()\n",
    "        \n",
    "        # Handle exit condition\n",
    "        if selection == \"exit\":\n",
    "            return []\n",
    "        \n",
    "        # Handle select all condition  \n",
    "        if selection == \"all\":\n",
    "            return [idx[\"name\"] for idx in indices]\n",
    "        \n",
    "        # Parse individual number selections\n",
    "        try:\n",
    "            selected_indices = [\n",
    "                indices[int(num)-1][\"name\"]                    # Convert 1-based index to 0-based\n",
    "                for num in selection.split(\",\")               # Split comma-separated input\n",
    "                if num.strip().isdigit()                      # Validate numeric input\n",
    "            ]\n",
    "            if selected_indices:\n",
    "                return list(set(selected_indices))            # Remove duplicates and return\n",
    "            print(\"‚ö†Ô∏è No valid selection. Please try again.\")\n",
    "        except (IndexError, ValueError):\n",
    "            print(\"‚õî Invalid input format. Use numbers separated by commas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def parse_utc_time(time_str):\n",
    "    \"\"\"\n",
    "    Parse human-readable time string into UTC datetime object.\n",
    "    \n",
    "    Args:\n",
    "        time_str (str): Time string in format \"Jan 29, 2025 @ 04:24:54.863\"\n",
    "        \n",
    "    Returns:\n",
    "        datetime: UTC datetime object, None if parsing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove any trailing timezone indicators (assume UTC)\n",
    "        time_str = time_str.split(\" (UTC)\")[0].strip()\n",
    "        \n",
    "        # Parse using predefined format and set UTC timezone\n",
    "        return datetime.strptime(time_str, TIMESTAMP_FORMAT).replace(tzinfo=timezone.utc)\n",
    "    except ValueError as e:\n",
    "        print(f\"‚è∞ Time parsing error: {e}\")\n",
    "        print(f\"üìÖ Expected format: {TIMESTAMP_FORMAT} (UTC)\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def export_index_data(es, index_name, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Export data from specific index within time range to JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        es (Elasticsearch): Elasticsearch client instance\n",
    "        index_name (str): Name of index to export\n",
    "        start_time (datetime): Start of time range (UTC)\n",
    "        end_time (datetime): End of time range (UTC)\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if export successful, False otherwise\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create safe filename from index name\n",
    "    safe_name = index_name.replace(\":\", \"_\").replace(\".\", \"-\")\n",
    "    filename = os.path.join(output_dir, f\"{safe_name}.jsonl\")\n",
    "    \n",
    "    # Build Elasticsearch query for time range filtering\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"range\": {\n",
    "                \"@timestamp\": {                                # Filter by timestamp field\n",
    "                    \"gte\": start_time.isoformat(),            # Greater than or equal to start\n",
    "                    \"lte\": end_time.isoformat(),              # Less than or equal to end\n",
    "                    \"format\": \"strict_date_optional_time\"     # ISO 8601 format\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Open output file and stream data\n",
    "        with open(filename, \"w\") as f:\n",
    "            count = 0\n",
    "            # Use scan helper for efficient scrolling through large result sets\n",
    "            for hit in scan(es, index=index_name, query=query):\n",
    "                # Write each document as single JSON line\n",
    "                f.write(json.dumps(hit[\"_source\"]) + \"\\n\")\n",
    "                count += 1\n",
    "                \n",
    "        print(f\"‚úÖ Success: {count} documents from {index_name} -> {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to export {index_name}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main orchestration function that coordinates the data extraction workflow.\n",
    "    \n",
    "    Workflow steps:\n",
    "    1. Connect to Elasticsearch cluster\n",
    "    2. Discover relevant indices\n",
    "    3. Present indices for user selection\n",
    "    4. Get time range from user input\n",
    "    5. Extract data from selected indices\n",
    "    \"\"\"\n",
    "    # Step 1: Establish connection\n",
    "    print(\"\\nüîó Connecting to Elasticsearch...\")\n",
    "    es = connect_elasticsearch()\n",
    "    \n",
    "    if not test_connection(es):\n",
    "        print(\"üö® Could not establish connection to Elasticsearch\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Discover relevant indices\n",
    "    print(\"\\nüîç Searching for relevant indices...\")\n",
    "    indices = list_relevant_indices(es, keywords)\n",
    "    \n",
    "    if not indices:\n",
    "        print(\"ü§∑ No matching indices found\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Interactive index selection\n",
    "    selected_indices = display_indices_selector(indices)\n",
    "    if not selected_indices:\n",
    "        print(\"üö™ Exiting without download\")\n",
    "        return\n",
    "\n",
    "    # Step 4: Get time range from user\n",
    "    print(\"\\nüïí Time Range Selection (UTC)\")\n",
    "    print(\"üí° Example format: 'Jan 29, 2025 @ 04:24:54.863'\")\n",
    "    start_time = parse_utc_time(input(\"‚è±Ô∏è  Start time: \"))\n",
    "    end_time = parse_utc_time(input(\"‚è∞ End time: \"))\n",
    "    \n",
    "    # Validate time parameters\n",
    "    if not all([start_time, end_time]):\n",
    "        print(\"‚õî Invalid time parameters\")\n",
    "        return\n",
    "\n",
    "    # Step 5: Extract data from each selected index\n",
    "    print(\"\\n‚è≥ Starting data export...\")\n",
    "    for index in selected_indices:\n",
    "        export_index_data(es, index, start_time, end_time)\n",
    "\n",
    "    # Display final time range for confirmation\n",
    "    print(f'start time: {start_time}')\n",
    "    print(f'end time: {end_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute main workflow when script is run directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_utc_time(time_str):  # Corrected function name\n",
    "    \"\"\"Parse time string into UTC datetime object\"\"\"\n",
    "    try:\n",
    "        # Strip any trailing timezone identifiers (we assume UTC)\n",
    "        time_str = time_str.split(\" (UTC)\")[0].strip()\n",
    "        return datetime.strptime(time_str, TIMESTAMP_FORMAT).replace(tzinfo=timezone.utc)\n",
    "    except ValueError as e:\n",
    "        print(f\"‚è∞ Time parsing error: {e}\")\n",
    "        print(f\"üìÖ Expected format: {TIMESTAMP_FORMAT} (UTC)\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_index_data(es, index_name, start_time, end_time):\n",
    "    \"\"\"Export index data within time range to JSONL file\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    safe_name = index_name.replace(\":\", \"_\").replace(\".\", \"-\")\n",
    "    filename = os.path.join(output_dir, f\"{safe_name}.jsonl\")\n",
    "    \n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"range\": {\n",
    "                \"@timestamp\": {\n",
    "                    \"gte\": start_time.isoformat(),\n",
    "                    \"lte\": end_time.isoformat(),\n",
    "                    \"format\": \"strict_date_optional_time\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(filename, \"w\") as f:\n",
    "            count = 0\n",
    "            for hit in scan(es, index=index_name, query=query):\n",
    "                f.write(json.dumps(hit[\"_source\"]) + \"\\n\")\n",
    "                count += 1\n",
    "        print(f\"‚úÖ Success: {count} documents from {index_name} -> {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to export {index_name}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"\\nüîó Connecting to Elasticsearch...\")\n",
    "    es = connect_elasticsearch()\n",
    "    \n",
    "    if not test_connection(es):\n",
    "        print(\"üö® Could not establish connection to Elasticsearch\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüîç Searching for relevant indices...\")\n",
    "    indices = list_relevant_indices(es, keywords)\n",
    "    \n",
    "    if not indices:\n",
    "        print(\"ü§∑ No matching indices found\")\n",
    "        return\n",
    "\n",
    "    selected_indices = display_indices_selector(indices)\n",
    "    if not selected_indices:\n",
    "        print(\"üö™ Exiting without download\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüïí Time Range Selection (UTC)\")\n",
    "    print(\"üí° Example format: 'Jan 29, 2025 @ 04:24:54.863'\")\n",
    "    start_time = parse_utc_time(input(\"‚è±Ô∏è  Start time: \"))\n",
    "    end_time = parse_utc_time(input(\"‚è∞ End time: \"))\n",
    "    \n",
    "    if not all([start_time, end_time]):\n",
    "        print(\"‚õî Invalid time parameters\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n‚è≥ Starting data export...\")\n",
    "    for index in selected_indices:\n",
    "        export_index_data(es, index, start_time, end_time)\n",
    "\n",
    "    print(f'start time: {start_time}')\n",
    "    print(f'end time: {end_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Connecting to Elasticsearch...\n",
      "\n",
      "üîç Searching for relevant indices...\n",
      "\n",
      "üìÇ Found 13 relevant indices:\n",
      "  1. .ds-logs-network_traffic.dns-default-2025.03.10-000001 (114.2mb) [Created: 2025-03-10]\n",
      "  2. .ds-logs-network_traffic.tls-default-2025.03.10-000001 (52.7mb) [Created: 2025-03-10]\n",
      "  3. .ds-logs-network_traffic.icmp-default-2025.03.10-000001 (2mb) [Created: 2025-03-10]\n",
      "  4. .ds-logs-windows.sysmon_operational-default-2025.04.15-000002 (17.2gb) [Created: 2025-04-15]\n",
      "  5. .ds-logs-network_traffic.dhcpv4-default-2025.04.17-000001 (86.2kb) [Created: 2025-04-17]\n",
      "  6. .ds-logs-network_traffic.tls-default-2025.04.15-000002 (45.3mb) [Created: 2025-04-15]\n",
      "  7. .ds-logs-network_traffic.flow-default-2025.04.15-000002 (25.3gb) [Created: 2025-04-15]\n",
      "  8. .ds-logs-network_traffic.dns-default-2025.04.15-000002 (255.4mb) [Created: 2025-04-15]\n",
      "  9. .ds-logs-windows.sysmon_operational-default-2025.03.10-000001 (8.4gb) [Created: 2025-03-10]\n",
      " 10. .ds-logs-network_traffic.icmp-default-2025.04.15-000002 (7.6mb) [Created: 2025-04-15]\n",
      " 11. .ds-logs-network_traffic.http-default-2025.04.15-000002 (137.2mb) [Created: 2025-04-15]\n",
      " 12. .ds-logs-network_traffic.http-default-2025.03.10-000001 (30.1mb) [Created: 2025-03-10]\n",
      " 13. .ds-logs-network_traffic.flow-default-2025.03.10-000001 (4.8gb) [Created: 2025-03-10]\n",
      "\n",
      "üïí Time Range Selection (UTC)\n",
      "üí° Example format: 'Jan 29, 2025 @ 04:24:54.863'\n",
      "\n",
      "‚è≥ Starting data export...\n",
      "‚úÖ Success: 0 documents from .ds-logs-network_traffic.dns-default-2025.03.10-000001 -> ./-ds-logs-network_traffic-dns-default-2025-03-10-000001.jsonl\n",
      "‚úÖ Success: 0 documents from .ds-logs-network_traffic.tls-default-2025.03.10-000001 -> ./-ds-logs-network_traffic-tls-default-2025-03-10-000001.jsonl\n",
      "‚úÖ Success: 0 documents from .ds-logs-network_traffic.icmp-default-2025.03.10-000001 -> ./-ds-logs-network_traffic-icmp-default-2025-03-10-000001.jsonl\n",
      "‚úÖ Success: 570078 documents from .ds-logs-windows.sysmon_operational-default-2025.04.15-000002 -> ./-ds-logs-windows-sysmon_operational-default-2025-04-15-000002.jsonl\n",
      "‚úÖ Success: 0 documents from .ds-logs-network_traffic.dhcpv4-default-2025.04.17-000001 -> ./-ds-logs-network_traffic-dhcpv4-default-2025-04-17-000001.jsonl\n",
      "‚úÖ Success: 293 documents from .ds-logs-network_traffic.tls-default-2025.04.15-000002 -> ./-ds-logs-network_traffic-tls-default-2025-04-15-000002.jsonl\n",
      "‚úÖ Success: 1090212 documents from .ds-logs-network_traffic.flow-default-2025.04.15-000002 -> ./-ds-logs-network_traffic-flow-default-2025-04-15-000002.jsonl\n",
      "‚úÖ Success: 4928 documents from .ds-logs-network_traffic.dns-default-2025.04.15-000002 -> ./-ds-logs-network_traffic-dns-default-2025-04-15-000002.jsonl\n",
      "‚úÖ Success: 0 documents from .ds-logs-windows.sysmon_operational-default-2025.03.10-000001 -> ./-ds-logs-windows-sysmon_operational-default-2025-03-10-000001.jsonl\n",
      "‚úÖ Success: 249 documents from .ds-logs-network_traffic.icmp-default-2025.04.15-000002 -> ./-ds-logs-network_traffic-icmp-default-2025-04-15-000002.jsonl\n",
      "‚úÖ Success: 193 documents from .ds-logs-network_traffic.http-default-2025.04.15-000002 -> ./-ds-logs-network_traffic-http-default-2025-04-15-000002.jsonl\n",
      "‚úÖ Success: 0 documents from .ds-logs-network_traffic.http-default-2025.03.10-000001 -> ./-ds-logs-network_traffic-http-default-2025-03-10-000001.jsonl\n",
      "‚úÖ Success: 0 documents from .ds-logs-network_traffic.flow-default-2025.03.10-000001 -> ./-ds-logs-network_traffic-flow-default-2025-03-10-000001.jsonl\n",
      "start time: 2025-05-04 11:30:00+00:00\n",
      "end time: 2025-05-04 12:40:00+00:00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
