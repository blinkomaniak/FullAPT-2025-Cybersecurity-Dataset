{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç SYSMON EVENTS EXPLORATORY ANALYSIS\n",
    "\n",
    "This notebook performs comprehensive exploratory analysis on Windows Sysmon events stored in JSONL format from Elasticsearch. The analysis focuses on understanding event distribution, XML structure patterns, field availability, and data quality characteristics.\n",
    "\n",
    "**Target File**: `-ds-logs-windows-sysmon_operational-default-2025-05-04-000001.jsonl`  \n",
    "**Analysis Type**: 2A-SYSMON  \n",
    "**Purpose**: Understand Sysmon event structure for optimal CSV conversion strategy\n",
    "\n",
    "**Key Analysis Areas**:\n",
    "- Sysmon EventID distribution and frequency patterns\n",
    "- XML structure analysis and field extraction patterns\n",
    "- Computer/host distribution analysis\n",
    "- Temporal patterns and event timeline analysis\n",
    "- Field availability and completeness assessment\n",
    "- Data quality and parsing success rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis Configuration and Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSMON EVENTS EXPLORATORY ANALYSIS\n",
      "Analysis Type: 2A-SYSMON\n",
      "Generated: 2025-06-29 11:23:56\n",
      "Target File: -ds-logs-windows-sysmon_operational-default-2025-05-04-000001.jsonl\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis Configuration\n",
    "ANALYSIS_TYPE = \"2a-sysmon\"\n",
    "SAMPLE_SIZE = 200_000  # Number of samples to analyze\n",
    "TARGET_FILE = \"-ds-logs-windows-sysmon_operational-default-2025-05-04-000001.jsonl\"\n",
    "\n",
    "# Create organized output directory structure\n",
    "outputs_base_dir = \"outputs\"\n",
    "analysis_outputs_dir = f\"{outputs_base_dir}/{ANALYSIS_TYPE}\"\n",
    "os.makedirs(analysis_outputs_dir, exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_filename = f\"{analysis_outputs_dir}/{ANALYSIS_TYPE}_exploratory_analysis_{timestamp}.log\"\n",
    "\n",
    "def log_print(message):\n",
    "    \"\"\"Print and log messages\"\"\"\n",
    "    print(message)\n",
    "    with open(log_filename, 'a', encoding='utf-8') as f:\n",
    "        f.write(message + '\\n')\n",
    "\n",
    "# Initialize log file\n",
    "log_print(\"SYSMON EVENTS EXPLORATORY ANALYSIS\")\n",
    "log_print(f\"Analysis Type: {ANALYSIS_TYPE.upper()}\")\n",
    "log_print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "log_print(f\"Target File: {TARGET_FILE}\")\n",
    "log_print(\"=\" * 80)\n",
    "log_print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XML Parsing Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ XML parsing utilities loaded\n"
     ]
    }
   ],
   "source": [
    "def sanitize_xml(xml_str):\n",
    "    \"\"\"Clean invalid characters and repair XML structure\"\"\"\n",
    "    try:\n",
    "        # Remove non-printable characters\n",
    "        cleaned = ''.join(c for c in xml_str if 31 < ord(c) < 127 or c in '\\t\\n\\r')\n",
    "        # Fix common XML issues using BeautifulSoup's parser\n",
    "        return BeautifulSoup(cleaned, \"xml\").prettify()\n",
    "    except:\n",
    "        return xml_str  # Return original if cleaning fails\n",
    "\n",
    "def parse_sysmon_event_basic(xml_str):\n",
    "    \"\"\"Parse XML to extract basic event information\"\"\"\n",
    "    try:\n",
    "        # Clean XML first\n",
    "        clean_xml = sanitize_xml(xml_str)\n",
    "        \n",
    "        # Parse with explicit namespace\n",
    "        namespaces = {'ns': 'http://schemas.microsoft.com/win/2004/08/events/event'}\n",
    "        root = ET.fromstring(clean_xml)\n",
    "        \n",
    "        # System section\n",
    "        system = root.find('ns:System', namespaces)\n",
    "        if not system:\n",
    "            return None, None, None, {}\n",
    "\n",
    "        event_id_elem = system.find('ns:EventID', namespaces)\n",
    "        computer_elem = system.find('ns:Computer', namespaces)\n",
    "        \n",
    "        event_id = int(event_id_elem.text) if event_id_elem is not None and event_id_elem.text else None\n",
    "        computer = computer_elem.text if computer_elem is not None and computer_elem.text else None\n",
    "\n",
    "        # EventData section - extract all fields\n",
    "        event_data = root.find('ns:EventData', namespaces)\n",
    "        fields = {}\n",
    "        if event_data:\n",
    "            for data in event_data.findall('ns:Data', namespaces):\n",
    "                name = data.get('Name')\n",
    "                if name:\n",
    "                    fields[name] = data.text if data.text else None\n",
    "\n",
    "        return event_id, computer, len(fields), fields\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, None, None, {}\n",
    "\n",
    "print(\"‚úÖ XML parsing utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 3: INITIAL DATA LOADING AND RECORD COUNT\n",
      "================================================================================\n",
      "\n",
      "üîÑ Counting total records in: -ds-logs-windows-sysmon_operational-default-2025-05-04-000001.jsonl\n",
      "üìà Total records in dataset: 570,078\n",
      "üéØ Sampling strategy: Will analyze 200,000 random samples\n",
      "üìä Selected 200,000 random indices for analysis\n",
      "\n",
      "------------------------------------------------------------ END SECTION ------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start section logging\n",
    "log_print(\"\\n\" + \"=\" * 80)\n",
    "log_print(\"SECTION 3: INITIAL DATA LOADING AND RECORD COUNT\")\n",
    "log_print(\"=\" * 80)\n",
    "log_print(\"\")\n",
    "\n",
    "# Count total records\n",
    "log_print(f\"üîÑ Counting total records in: {TARGET_FILE}\")\n",
    "total_records = 0\n",
    "with open(TARGET_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        total_records += 1\n",
    "\n",
    "log_print(f\"üìà Total records in dataset: {total_records:,}\")\n",
    "log_print(f\"üéØ Sampling strategy: Will analyze {SAMPLE_SIZE:,} random samples\")\n",
    "\n",
    "# Random sampling strategy\n",
    "random.seed()  # Use truly random seed for different results each run\n",
    "sample_indices = set(random.sample(range(total_records), min(SAMPLE_SIZE, total_records)))\n",
    "\n",
    "log_print(f\"üìä Selected {len(sample_indices):,} random indices for analysis\")\n",
    "\n",
    "# End section logging\n",
    "log_print(\"\\n\" + \"-\" * 60 + \" END SECTION \" + \"-\" * 60)\n",
    "log_print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic Event Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 4: BASIC EVENT STRUCTURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìã BASIC EVENT STRUCTURE ANALYSIS\n",
      "==================================================\n",
      "üîç Data type: <class 'dict'>\n",
      "üìè Number of top-level fields: 18\n",
      "üóùÔ∏è  Top-level fields:\n",
      "    1. agent                          (dict)\n",
      "    2. process                        (dict)\n",
      "    3. winlog                         (dict)\n",
      "    4. log                            (dict)\n",
      "    5. elastic_agent                  (dict)\n",
      "    6. destination                    (dict)\n",
      "    7. source                         (dict)\n",
      "    8. message                        (str)\n",
      "    9. tags                           (list)\n",
      "   10. network                        (dict)\n",
      "   11. input                          (dict)\n",
      "   12. @timestamp                     (str)\n",
      "   13. ecs                            (dict)\n",
      "   14. related                        (dict)\n",
      "   15. data_stream                    (dict)\n",
      "   16. host                           (dict)\n",
      "   17. event                          (dict)\n",
      "   18. user                           (dict)\n",
      "\n",
      "üìÑ XML content sample (first 500 chars):\n",
      "--------------------------------------------------\n",
      "<Event xmlns='http://schemas.microsoft.com/win/2004/08/events/event'><System><Provider Name='Microsoft-Windows-Sysmon' Guid='{5770385f-c22a-43e0-bf4c-06f5698ffbd9}'/><EventID>3</EventID><Version>5</Version><Level>4</Level><Task>3</Task><Opcode>0</Opcode><Keywords>0x8000000000000000</Keywords><TimeCreated SystemTime='2025-05-04T11:30:03.299859800Z'/><EventRecordID>2539113</EventRecordID><Correlation/><Execution ProcessID='2716' ThreadID='3140'/><Channel>Microsoft-Windows-Sysmon/Operational</Chann...\n",
      "\n",
      "üéØ XML parsing results:\n",
      "   ‚Ä¢ EventID: 3\n",
      "   ‚Ä¢ Computer: \n",
      "   diskjockey.boombox.local\n",
      "  \n",
      "   ‚Ä¢ Field count: 18\n",
      "   ‚Ä¢ Available fields: ['RuleName', 'UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'User', 'Protocol', 'Initiated', 'SourceIsIpv6', 'SourceIp']...\n",
      "\n",
      "üìä Complete first sample structure:\n",
      "--------------------------------------------------\n",
      "{'agent': {'name': 'diskjockey', 'id': '15638b02-c77f-4aed-9566-1c5c68f1c0b3', 'ephemeral_id': '903dc2e3-ce5b-4a53-bb39-3347fdb5bb65', 'type': 'filebeat', 'version': '8.18.0'}, 'process': {'name': 'dns.exe', 'pid': 2608, 'entity_id': '{acb80d05-4f9d-6817-3400-000000001600}', 'executable': 'C:\\\\Windows\\\\System32\\\\dns.exe'}, 'winlog': {'computer_name': 'diskjockey.boombox.local', 'process': {'pid': 2716, 'thread': {'id': 3140}}, 'channel': 'Microsoft-Windows-Sysmon/Operational', 'opcode': 'Info', 'version': 5, 'record_id': '2539113', 'event_id': '3', 'task': 'Network connection detected (rule: NetworkConnect)', 'provider_guid': '{5770385f-c22a-43e0-bf4c-06f5698ffbd9}', 'api': 'wineventlog', 'provider_name': 'Microsoft-Windows-Sysmon', 'user': {'identifier': 'S-1-5-18', 'domain': 'NT AUTHORITY', 'name': 'SYSTEM', 'type': 'User'}}, 'log': {'level': 'information'}, 'elastic_agent': {'id': '15638b02-c77f-4aed-9566-1c5c68f1c0b3', 'version': '8.18.0', 'snapshot': False}, 'destination': {'port'...\n",
      "\n",
      "------------------------------------------------------------ END SECTION ------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start section logging\n",
    "log_print(\"\\n\" + \"=\" * 80)\n",
    "log_print(\"SECTION 4: BASIC EVENT STRUCTURE ANALYSIS\")\n",
    "log_print(\"=\" * 80)\n",
    "log_print(\"\")\n",
    "\n",
    "# Load and analyze sample data\n",
    "log_print(\"üìã BASIC EVENT STRUCTURE ANALYSIS\")\n",
    "log_print(\"=\" * 50)\n",
    "\n",
    "# Analyze first record structure\n",
    "sample_data = []\n",
    "current_index = 0\n",
    "\n",
    "with open(TARGET_FILE, 'r') as f:\n",
    "    for line_number, line in enumerate(f):\n",
    "        if line_number in sample_indices:\n",
    "            try:\n",
    "                event = json.loads(line)\n",
    "                sample_data.append(event)\n",
    "                if len(sample_data) >= 10:  # Get first 10 for structure analysis\n",
    "                    break\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "if sample_data:\n",
    "    first_sample = sample_data[0]\n",
    "    log_print(f\"üîç Data type: {type(first_sample)}\")\n",
    "    log_print(f\"üìè Number of top-level fields: {len(first_sample)}\")\n",
    "    log_print(f\"üóùÔ∏è  Top-level fields:\")\n",
    "    \n",
    "    for idx, key in enumerate(first_sample.keys(), 1):\n",
    "        value_type = type(first_sample[key]).__name__\n",
    "        log_print(f\"   {idx:2d}. {key:30s} ({value_type})\")\n",
    "    \n",
    "    # Analyze the XML structure\n",
    "    if 'event' in first_sample and 'original' in first_sample['event']:\n",
    "        xml_content = first_sample['event']['original']\n",
    "        log_print(f\"\\nüìÑ XML content sample (first 500 chars):\")\n",
    "        log_print(\"-\" * 50)\n",
    "        log_print(xml_content[:500] + \"...\" if len(xml_content) > 500 else xml_content)\n",
    "        \n",
    "        # Parse the XML to understand structure\n",
    "        event_id, computer, field_count, fields = parse_sysmon_event_basic(xml_content)\n",
    "        log_print(f\"\\nüéØ XML parsing results:\")\n",
    "        log_print(f\"   ‚Ä¢ EventID: {event_id}\")\n",
    "        log_print(f\"   ‚Ä¢ Computer: {computer}\")\n",
    "        log_print(f\"   ‚Ä¢ Field count: {field_count}\")\n",
    "        if fields:\n",
    "            log_print(f\"   ‚Ä¢ Available fields: {list(fields.keys())[:10]}{'...' if len(fields) > 10 else ''}\")\n",
    "    \n",
    "    log_print(f\"\\nüìä Complete first sample structure:\")\n",
    "    log_print(\"-\" * 50)\n",
    "    log_print(str(first_sample)[:1000] + \"...\" if len(str(first_sample)) > 1000 else str(first_sample))\n",
    "\n",
    "# End section logging\n",
    "log_print(\"\\n\" + \"-\" * 60 + \" END SECTION \" + \"-\" * 60)\n",
    "log_print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. EventID Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 5: EVENTID DISTRIBUTION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìä EVENTID DISTRIBUTION ANALYSIS\n",
      "==================================================\n",
      "üîÑ Processing 200,000 samples for EventID analysis...\n",
      "   Processed 10,000 samples...\n",
      "   Processed 20,000 samples...\n",
      "   Processed 30,000 samples...\n",
      "   Processed 40,000 samples...\n",
      "   Processed 50,000 samples...\n",
      "   Processed 60,000 samples...\n",
      "   Processed 70,000 samples...\n",
      "   Processed 80,000 samples...\n",
      "   Processed 90,000 samples...\n",
      "   Processed 100,000 samples...\n",
      "   Processed 110,000 samples...\n",
      "   Processed 120,000 samples...\n",
      "   Processed 130,000 samples...\n",
      "   Processed 140,000 samples...\n",
      "   Processed 150,000 samples...\n",
      "   Processed 160,000 samples...\n",
      "   Processed 170,000 samples...\n",
      "   Processed 180,000 samples...\n",
      "   Processed 190,000 samples...\n",
      "   Processed 200,000 samples...\n",
      "\n",
      "‚úÖ Analysis complete!\n",
      "üìà Samples processed: 200,000\n",
      "üìä Parsing success: 200,000 (100.0%)\n",
      "‚ö†Ô∏è  Parsing errors: 0 (0.0%)\n",
      "\n",
      "üéØ EVENTID FREQUENCY DISTRIBUTION:\n",
      "Event ID | Count    | Percentage | Description\n",
      "------------------------------------------------------------\n",
      "      12 |  101,377 |     50.69% | Registry Event (Object create/delete)\n",
      "      13 |   45,392 |     22.70% | Registry Event (Value Set)\n",
      "       7 |   22,773 |     11.39% | Image/Library Loaded\n",
      "      10 |   20,345 |     10.17% | Process Access\n",
      "       3 |    5,795 |      2.90% | Network Connection\n",
      "      11 |    1,448 |      0.72% | File Create\n",
      "      23 |      719 |      0.36% | File Delete (File Delete archived)\n",
      "       1 |      527 |      0.26% | Process Creation\n",
      "      18 |      502 |      0.25% | Pipe Event (Pipe Connected)\n",
      "       9 |      394 |      0.20% | Raw Access Read\n",
      "       5 |      313 |      0.16% | Process Terminated\n",
      "       6 |      188 |      0.09% | Driver Loaded\n",
      "      17 |      182 |      0.09% | Pipe Event (Pipe Created)\n",
      "       2 |       26 |      0.01% | File Creation Time Changed\n",
      "      15 |       15 |      0.01% | File Create Stream Hash\n",
      "      25 |        3 |      0.00% | Process Tampering (Process image change)\n",
      "       4 |        1 |      0.00% | Sysmon Service State Changed\n",
      "\n",
      "üñ•Ô∏è COMPUTER/HOST DISTRIBUTION:\n",
      "üìä Unique computers: 4\n",
      "Computer Name        | Count    | Percentage\n",
      "--------------------------------------------------\n",
      "\n",
      "   theblock.boombox.local\n",
      "   |  122,771 |     61.39%\n",
      "\n",
      "   waterfalls.boombox.local\n",
      "   |   30,929 |     15.46%\n",
      "\n",
      "   diskjockey.boombox.local\n",
      "   |   24,788 |     12.39%\n",
      "\n",
      "   endofroad.boombox.local\n",
      "   |   21,512 |     10.76%\n",
      "\n",
      "------------------------------------------------------------ END SECTION ------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start section logging\n",
    "log_print(\"\\n\" + \"=\" * 80)\n",
    "log_print(\"SECTION 5: EVENTID DISTRIBUTION ANALYSIS\")\n",
    "log_print(\"=\" * 80)\n",
    "log_print(\"\")\n",
    "\n",
    "log_print(\"üìä EVENTID DISTRIBUTION ANALYSIS\")\n",
    "log_print(\"=\" * 50)\n",
    "\n",
    "# Analyze EventID distribution\n",
    "eventid_counts = Counter()\n",
    "computer_counts = Counter()\n",
    "parsing_success = 0\n",
    "parsing_errors = 0\n",
    "samples_processed = 0\n",
    "\n",
    "log_print(f\"üîÑ Processing {len(sample_indices):,} samples for EventID analysis...\")\n",
    "\n",
    "with open(TARGET_FILE, 'r') as f:\n",
    "    for line_number, line in enumerate(f):\n",
    "        if line_number in sample_indices:\n",
    "            samples_processed += 1\n",
    "            try:\n",
    "                event = json.loads(line)\n",
    "                if 'event' in event and 'original' in event['event']:\n",
    "                    xml_content = event['event']['original']\n",
    "                    event_id, computer, field_count, fields = parse_sysmon_event_basic(xml_content)\n",
    "                    \n",
    "                    if event_id is not None:\n",
    "                        eventid_counts[event_id] += 1\n",
    "                        parsing_success += 1\n",
    "                        \n",
    "                        if computer:\n",
    "                            computer_counts[computer] += 1\n",
    "                    else:\n",
    "                        parsing_errors += 1\n",
    "                else:\n",
    "                    parsing_errors += 1\n",
    "                    \n",
    "            except (json.JSONDecodeError, Exception):\n",
    "                parsing_errors += 1\n",
    "            \n",
    "            # Progress indicator\n",
    "            if samples_processed % 10000 == 0:\n",
    "                log_print(f\"   Processed {samples_processed:,} samples...\")\n",
    "\n",
    "log_print(f\"\\n‚úÖ Analysis complete!\")\n",
    "log_print(f\"üìà Samples processed: {samples_processed:,}\")\n",
    "log_print(f\"üìä Parsing success: {parsing_success:,} ({(parsing_success/samples_processed)*100:.1f}%)\")\n",
    "log_print(f\"‚ö†Ô∏è  Parsing errors: {parsing_errors:,} ({(parsing_errors/samples_processed)*100:.1f}%)\")\n",
    "\n",
    "# EventID distribution\n",
    "log_print(f\"\\nüéØ EVENTID FREQUENCY DISTRIBUTION:\")\n",
    "log_print(\"Event ID | Count    | Percentage | Description\")\n",
    "log_print(\"-\" * 60)\n",
    "\n",
    "# Sysmon EventID descriptions for context\n",
    "eventid_descriptions = {\n",
    "    1: \"Process Creation\",\n",
    "    2: \"File Creation Time Changed\", \n",
    "    3: \"Network Connection\",\n",
    "    4: \"Sysmon Service State Changed\",\n",
    "    5: \"Process Terminated\",\n",
    "    6: \"Driver Loaded\",\n",
    "    7: \"Image/Library Loaded\",\n",
    "    8: \"Create Remote Thread\",\n",
    "    9: \"Raw Access Read\",\n",
    "    10: \"Process Access\",\n",
    "    11: \"File Create\",\n",
    "    12: \"Registry Event (Object create/delete)\",\n",
    "    13: \"Registry Event (Value Set)\",\n",
    "    14: \"Registry Event (Key/Value Rename)\",\n",
    "    15: \"File Create Stream Hash\",\n",
    "    16: \"Sysmon Config State Changed\",\n",
    "    17: \"Pipe Event (Pipe Created)\",\n",
    "    18: \"Pipe Event (Pipe Connected)\",\n",
    "    19: \"WMI Event (WmiEventFilter activity)\",\n",
    "    20: \"WMI Event (WmiEventConsumer activity)\",\n",
    "    21: \"WMI Event (WmiEventConsumerToFilter activity)\",\n",
    "    22: \"DNS Event (DNS query)\",\n",
    "    23: \"File Delete (File Delete archived)\",\n",
    "    24: \"Clipboard Change (New content in clipboard)\",\n",
    "    25: \"Process Tampering (Process image change)\",\n",
    "    26: \"File Delete (File Delete logged)\"\n",
    "}\n",
    "\n",
    "for event_id, count in eventid_counts.most_common():\n",
    "    percentage = (count / parsing_success) * 100\n",
    "    description = eventid_descriptions.get(event_id, \"Unknown EventID\")\n",
    "    log_print(f\"{event_id:8d} | {count:8,} | {percentage:9.2f}% | {description}\")\n",
    "\n",
    "# Computer distribution\n",
    "log_print(f\"\\nüñ•Ô∏è COMPUTER/HOST DISTRIBUTION:\")\n",
    "log_print(f\"üìä Unique computers: {len(computer_counts)}\")\n",
    "log_print(\"Computer Name        | Count    | Percentage\")\n",
    "log_print(\"-\" * 50)\n",
    "\n",
    "for computer, count in computer_counts.most_common(10):  # Top 10 computers\n",
    "    percentage = (count / parsing_success) * 100\n",
    "    log_print(f\"{computer:20s} | {count:8,} | {percentage:9.2f}%\")\n",
    "\n",
    "if len(computer_counts) > 10:\n",
    "    log_print(f\"... and {len(computer_counts) - 10} more computers\")\n",
    "\n",
    "# End section logging\n",
    "log_print(\"\\n\" + \"-\" * 60 + \" END SECTION \" + \"-\" * 60)\n",
    "log_print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Field Availability Analysis by EventID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 6: FIELD AVAILABILITY ANALYSIS BY EVENTID\n",
      "================================================================================\n",
      "\n",
      "üìä FIELD AVAILABILITY ANALYSIS BY EVENTID\n",
      "==================================================\n",
      "üîÑ Analyzing field availability across 200,000 samples...\n",
      "\n",
      "üìã FIELD AVAILABILITY REPORT:\n",
      "============================================================\n",
      "\n",
      "üéØ EventID 1 (Process Creation)\n",
      "   üìä Analyzed samples: 527\n",
      "   üìã Expected fields: 12\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :    527/527 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :    527/527 (100.0%)\n",
      "   ‚úÖ ProcessId                :    527/527 (100.0%)\n",
      "   ‚úÖ Image                    :    527/527 (100.0%)\n",
      "   ‚úÖ CommandLine              :    527/527 (100.0%)\n",
      "   ‚úÖ CurrentDirectory         :    527/527 (100.0%)\n",
      "   ‚úÖ User                     :    527/527 (100.0%)\n",
      "   ‚úÖ Hashes                   :    527/527 (100.0%)\n",
      "   ‚úÖ ParentProcessGuid        :    527/527 (100.0%)\n",
      "   ‚úÖ ParentProcessId          :    527/527 (100.0%)\n",
      "   ‚úÖ ParentImage              :    527/527 (100.0%)\n",
      "   ‚úÖ ParentCommandLine        :    527/527 (100.0%)\n",
      "\n",
      "üéØ EventID 2 (File Creation Time Changed)\n",
      "   üìä Analyzed samples: 26\n",
      "   üìã Expected fields: 8\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :     26/26 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :     26/26 (100.0%)\n",
      "   ‚úÖ ProcessId                :     26/26 (100.0%)\n",
      "   ‚úÖ Image                    :     26/26 (100.0%)\n",
      "   ‚úÖ TargetFilename           :     26/26 (100.0%)\n",
      "   ‚úÖ CreationUtcTime          :     26/26 (100.0%)\n",
      "   ‚úÖ PreviousCreationUtcTime  :     26/26 (100.0%)\n",
      "   ‚úÖ User                     :     26/26 (100.0%)\n",
      "\n",
      "üéØ EventID 3 (Network Connection)\n",
      "   üìä Analyzed samples: 5,795\n",
      "   üìã Expected fields: 16\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ ProcessId                :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ Image                    :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ User                     :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ Protocol                 :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ SourceIsIpv6             :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ SourceIp                 :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ SourceHostname           :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ SourcePort               :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ SourcePortName           :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ DestinationIsIpv6        :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ DestinationIp            :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ DestinationHostname      :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ DestinationPort          :  5,795/5,795 (100.0%)\n",
      "   ‚úÖ DestinationPortName      :  5,795/5,795 (100.0%)\n",
      "\n",
      "üéØ EventID 5 (Process Terminated)\n",
      "   üìä Analyzed samples: 313\n",
      "   üìã Expected fields: 5\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :    313/313 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :    313/313 (100.0%)\n",
      "   ‚úÖ ProcessId                :    313/313 (100.0%)\n",
      "   ‚úÖ Image                    :    313/313 (100.0%)\n",
      "   ‚úÖ User                     :    313/313 (100.0%)\n",
      "\n",
      "üéØ EventID 6 (Driver Loaded)\n",
      "   üìä Analyzed samples: 188\n",
      "   üìã Expected fields: 4\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :    188/188 (100.0%)\n",
      "   ‚úÖ ImageLoaded              :    188/188 (100.0%)\n",
      "   ‚úÖ Hashes                   :    188/188 (100.0%)\n",
      "   ‚ùå User                     :      0/188 (  0.0%)\n",
      "\n",
      "üéØ EventID 7 (Image/Library Loaded)\n",
      "   üìä Analyzed samples: 22,773\n",
      "   üìã Expected fields: 8\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  : 22,773/22,773 (100.0%)\n",
      "   ‚úÖ ProcessGuid              : 22,773/22,773 (100.0%)\n",
      "   ‚úÖ ProcessId                : 22,773/22,773 (100.0%)\n",
      "   ‚úÖ Image                    : 22,773/22,773 (100.0%)\n",
      "   ‚úÖ ImageLoaded              : 22,773/22,773 (100.0%)\n",
      "   ‚úÖ OriginalFileName         : 22,773/22,773 (100.0%)\n",
      "   ‚úÖ Hashes                   : 22,773/22,773 (100.0%)\n",
      "   ‚úÖ User                     : 22,773/22,773 (100.0%)\n",
      "\n",
      "üéØ EventID 9 (Raw Access Read)\n",
      "   üìä Analyzed samples: 394\n",
      "   üìã Expected fields: 6\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :    394/394 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :    394/394 (100.0%)\n",
      "   ‚úÖ ProcessId                :    394/394 (100.0%)\n",
      "   ‚úÖ Image                    :    394/394 (100.0%)\n",
      "   ‚úÖ Device                   :    394/394 (100.0%)\n",
      "   ‚úÖ User                     :    394/394 (100.0%)\n",
      "\n",
      "üéØ EventID 10 (Process Access)\n",
      "   üìä Analyzed samples: 20,345\n",
      "   üìã Expected fields: 10\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  : 20,345/20,345 (100.0%)\n",
      "   ‚úÖ SourceProcessGUID        : 20,345/20,345 (100.0%)\n",
      "   ‚úÖ SourceProcessId          : 20,345/20,345 (100.0%)\n",
      "   ‚úÖ SourceImage              : 20,345/20,345 (100.0%)\n",
      "   ‚úÖ TargetProcessGUID        : 20,345/20,345 (100.0%)\n",
      "   ‚úÖ TargetProcessId          : 20,345/20,345 (100.0%)\n",
      "   ‚úÖ TargetImage              : 20,345/20,345 (100.0%)\n",
      "   ‚úÖ SourceThreadId           : 20,345/20,345 (100.0%)\n",
      "   ‚úÖ SourceUser               : 20,345/20,345 (100.0%)\n",
      "   ‚úÖ TargetUser               : 20,345/20,345 (100.0%)\n",
      "\n",
      "üéØ EventID 11 (File Create)\n",
      "   üìä Analyzed samples: 1,448\n",
      "   üìã Expected fields: 7\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :  1,448/1,448 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :  1,448/1,448 (100.0%)\n",
      "   ‚úÖ ProcessId                :  1,448/1,448 (100.0%)\n",
      "   ‚úÖ Image                    :  1,448/1,448 (100.0%)\n",
      "   ‚úÖ TargetFilename           :  1,448/1,448 (100.0%)\n",
      "   ‚úÖ CreationUtcTime          :  1,448/1,448 (100.0%)\n",
      "   ‚úÖ User                     :  1,448/1,448 (100.0%)\n",
      "\n",
      "üéØ EventID 12 (Registry Event (Object create/delete))\n",
      "   üìä Analyzed samples: 101,377\n",
      "   üìã Expected fields: 7\n",
      "   Field Availability:\n",
      "   ‚úÖ EventType                : 101,377/101,377 (100.0%)\n",
      "   ‚úÖ UtcTime                  : 101,377/101,377 (100.0%)\n",
      "   ‚úÖ ProcessGuid              : 101,377/101,377 (100.0%)\n",
      "   ‚úÖ ProcessId                : 101,377/101,377 (100.0%)\n",
      "   ‚úÖ Image                    : 101,377/101,377 (100.0%)\n",
      "   ‚úÖ TargetObject             : 101,377/101,377 (100.0%)\n",
      "   ‚úÖ User                     : 101,377/101,377 (100.0%)\n",
      "\n",
      "üéØ EventID 13 (Registry Event (Value Set))\n",
      "   üìä Analyzed samples: 45,392\n",
      "   üìã Expected fields: 7\n",
      "   Field Availability:\n",
      "   ‚úÖ EventType                : 45,392/45,392 (100.0%)\n",
      "   ‚úÖ UtcTime                  : 45,392/45,392 (100.0%)\n",
      "   ‚úÖ ProcessGuid              : 45,392/45,392 (100.0%)\n",
      "   ‚úÖ ProcessId                : 45,392/45,392 (100.0%)\n",
      "   ‚úÖ Image                    : 45,392/45,392 (100.0%)\n",
      "   ‚úÖ TargetObject             : 45,392/45,392 (100.0%)\n",
      "   ‚úÖ User                     : 45,392/45,392 (100.0%)\n",
      "\n",
      "üéØ EventID 15 (File Create Stream Hash)\n",
      "   üìä Analyzed samples: 15\n",
      "   üìã Expected fields: 8\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :     15/15 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :     15/15 (100.0%)\n",
      "   ‚úÖ ProcessId                :     15/15 (100.0%)\n",
      "   ‚úÖ Image                    :     15/15 (100.0%)\n",
      "   ‚úÖ TargetFilename           :     15/15 (100.0%)\n",
      "   ‚úÖ CreationUtcTime          :     15/15 (100.0%)\n",
      "   ‚úÖ Hash                     :     15/15 (100.0%)\n",
      "   ‚ö†Ô∏è User                     :     13/15 ( 86.7%)\n",
      "\n",
      "üéØ EventID 17 (Pipe Event (Pipe Created))\n",
      "   üìä Analyzed samples: 182\n",
      "   üìã Expected fields: 7\n",
      "   Field Availability:\n",
      "   ‚úÖ EventType                :    182/182 (100.0%)\n",
      "   ‚úÖ UtcTime                  :    182/182 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :    182/182 (100.0%)\n",
      "   ‚úÖ ProcessId                :    182/182 (100.0%)\n",
      "   ‚úÖ PipeName                 :    182/182 (100.0%)\n",
      "   ‚úÖ Image                    :    182/182 (100.0%)\n",
      "   ‚úÖ User                     :    182/182 (100.0%)\n",
      "\n",
      "üéØ EventID 18 (Pipe Event (Pipe Connected))\n",
      "   üìä Analyzed samples: 502\n",
      "   üìã Expected fields: 7\n",
      "   Field Availability:\n",
      "   ‚úÖ EventType                :    502/502 (100.0%)\n",
      "   ‚úÖ UtcTime                  :    502/502 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :    502/502 (100.0%)\n",
      "   ‚úÖ ProcessId                :    502/502 (100.0%)\n",
      "   ‚úÖ PipeName                 :    502/502 (100.0%)\n",
      "   ‚úÖ Image                    :    502/502 (100.0%)\n",
      "   ‚úÖ User                     :    502/502 (100.0%)\n",
      "\n",
      "üéØ EventID 23 (File Delete (File Delete archived))\n",
      "   üìä Analyzed samples: 719\n",
      "   üìã Expected fields: 7\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :    719/719 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :    719/719 (100.0%)\n",
      "   ‚úÖ ProcessId                :    719/719 (100.0%)\n",
      "   ‚úÖ User                     :    719/719 (100.0%)\n",
      "   ‚úÖ Image                    :    719/719 (100.0%)\n",
      "   ‚úÖ TargetFilename           :    719/719 (100.0%)\n",
      "   ‚úÖ Hashes                   :    719/719 (100.0%)\n",
      "\n",
      "üéØ EventID 25 (Process Tampering (Process image change))\n",
      "   üìä Analyzed samples: 3\n",
      "   üìã Expected fields: 5\n",
      "   Field Availability:\n",
      "   ‚úÖ UtcTime                  :      3/3 (100.0%)\n",
      "   ‚úÖ ProcessGuid              :      3/3 (100.0%)\n",
      "   ‚úÖ ProcessId                :      3/3 (100.0%)\n",
      "   ‚úÖ User                     :      3/3 (100.0%)\n",
      "   ‚úÖ Image                    :      3/3 (100.0%)\n",
      "\n",
      "üìä FIELD AVAILABILITY SUMMARY:\n",
      "========================================\n",
      "‚Ä¢ Total EventIDs analyzed: 16\n",
      "‚Ä¢ Total fields analyzed: 124\n",
      "‚Ä¢ Field availability varies significantly by EventID\n",
      "‚Ä¢ Some fields may be conditionally present based on event context\n",
      "\n",
      "------------------------------------------------------------ END SECTION ------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start section logging\n",
    "log_print(\"\\n\" + \"=\" * 80)\n",
    "log_print(\"SECTION 6: FIELD AVAILABILITY ANALYSIS BY EVENTID\")\n",
    "log_print(\"=\" * 80)\n",
    "log_print(\"\")\n",
    "\n",
    "log_print(\"üìä FIELD AVAILABILITY ANALYSIS BY EVENTID\")\n",
    "log_print(\"=\" * 50)\n",
    "\n",
    "# Sysmon field schemas from notebook #2\n",
    "fields_per_eventid = {\n",
    "    1: ['UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'CommandLine', 'CurrentDirectory', 'User', 'Hashes', 'ParentProcessGuid', 'ParentProcessId', 'ParentImage', 'ParentCommandLine'],\n",
    "    2: ['UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'TargetFilename', 'CreationUtcTime', 'PreviousCreationUtcTime', 'User'],\n",
    "    3: ['UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'User', 'Protocol', 'SourceIsIpv6', 'SourceIp', 'SourceHostname', 'SourcePort', 'SourcePortName', 'DestinationIsIpv6', 'DestinationIp', 'DestinationHostname', 'DestinationPort', 'DestinationPortName'],\n",
    "    5: ['UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'User'],\n",
    "    6: ['UtcTime', 'ImageLoaded', 'Hashes', 'User'],\n",
    "    7: ['UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'ImageLoaded', 'OriginalFileName', 'Hashes', 'User'],\n",
    "    8: ['UtcTime', 'SourceProcessGuid', 'SourceProcessId', 'SourceImage', 'TargetProcessGuid', 'TargetProcessId', 'TargetImage', 'NewThreadId', 'SourceUser', 'TargetUser'],\n",
    "    9: ['UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'Device', 'User'],\n",
    "    10: ['UtcTime', 'SourceProcessGUID', 'SourceProcessId', 'SourceImage', 'TargetProcessGUID', 'TargetProcessId', 'TargetImage', 'SourceThreadId', 'SourceUser', 'TargetUser'],\n",
    "    11: ['UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'TargetFilename', 'CreationUtcTime', 'User'],\n",
    "    12: ['EventType', 'UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'TargetObject', 'User'],\n",
    "    13: ['EventType', 'UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'TargetObject', 'User'],\n",
    "    15: ['UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'TargetFilename', 'CreationUtcTime', 'Hash', 'User'],\n",
    "    17: ['EventType', 'UtcTime', 'ProcessGuid', 'ProcessId', 'PipeName', 'Image', 'User'],\n",
    "    18: ['EventType', 'UtcTime', 'ProcessGuid', 'ProcessId', 'PipeName', 'Image', 'User'],\n",
    "    22: ['UtcTime', 'ProcessGuid', 'ProcessId', 'Image', 'QueryName', 'QueryStatus', 'QueryResults', 'User'],\n",
    "    23: ['UtcTime', 'ProcessGuid', 'ProcessId', 'User', 'Image', 'TargetFilename', 'Hashes'],\n",
    "    24: ['UtcTime', 'ProcessGuid', 'ProcessId', 'User', 'Image', 'Hashes'],\n",
    "    25: ['UtcTime', 'ProcessGuid', 'ProcessId', 'User', 'Image']\n",
    "}\n",
    "\n",
    "# Analyze field availability for each EventID\n",
    "field_analysis = {}\n",
    "samples_per_eventid = {}\n",
    "\n",
    "log_print(f\"üîÑ Analyzing field availability across {len(sample_indices):,} samples...\")\n",
    "\n",
    "with open(TARGET_FILE, 'r') as f:\n",
    "    for line_number, line in enumerate(f):\n",
    "        if line_number in sample_indices:\n",
    "            try:\n",
    "                event = json.loads(line)\n",
    "                if 'event' in event and 'original' in event['event']:\n",
    "                    xml_content = event['event']['original']\n",
    "                    event_id, computer, field_count, fields = parse_sysmon_event_basic(xml_content)\n",
    "                    \n",
    "                    if event_id is not None and event_id in fields_per_eventid:\n",
    "                        if event_id not in field_analysis:\n",
    "                            field_analysis[event_id] = {}\n",
    "                            samples_per_eventid[event_id] = 0\n",
    "                        \n",
    "                        samples_per_eventid[event_id] += 1\n",
    "                        \n",
    "                        # Check each expected field\n",
    "                        for expected_field in fields_per_eventid[event_id]:\n",
    "                            if expected_field not in field_analysis[event_id]:\n",
    "                                field_analysis[event_id][expected_field] = 0\n",
    "                            \n",
    "                            if expected_field in fields and fields[expected_field] is not None:\n",
    "                                field_analysis[event_id][expected_field] += 1\n",
    "                    \n",
    "            except (json.JSONDecodeError, Exception):\n",
    "                continue\n",
    "\n",
    "# Report field availability\n",
    "log_print(f\"\\nüìã FIELD AVAILABILITY REPORT:\")\n",
    "log_print(\"=\" * 60)\n",
    "\n",
    "for event_id in sorted(field_analysis.keys()):\n",
    "    total_samples = samples_per_eventid[event_id]\n",
    "    if total_samples > 0:\n",
    "        log_print(f\"\\nüéØ EventID {event_id} ({eventid_descriptions.get(event_id, 'Unknown')})\")\n",
    "        log_print(f\"   üìä Analyzed samples: {total_samples:,}\")\n",
    "        log_print(f\"   üìã Expected fields: {len(fields_per_eventid[event_id])}\")\n",
    "        log_print(\"   Field Availability:\")\n",
    "        \n",
    "        for field in fields_per_eventid[event_id]:\n",
    "            available_count = field_analysis[event_id].get(field, 0)\n",
    "            percentage = (available_count / total_samples) * 100\n",
    "            status = \"‚úÖ\" if percentage > 95 else \"‚ö†Ô∏è\" if percentage > 50 else \"‚ùå\"\n",
    "            log_print(f\"   {status} {field:25s}: {available_count:6,}/{total_samples:,} ({percentage:5.1f}%)\")\n",
    "\n",
    "# Summary statistics\n",
    "log_print(f\"\\nüìä FIELD AVAILABILITY SUMMARY:\")\n",
    "log_print(\"=\" * 40)\n",
    "\n",
    "total_eventids_analyzed = len(field_analysis)\n",
    "total_fields_analyzed = sum(len(fields_per_eventid[eid]) for eid in field_analysis.keys())\n",
    "\n",
    "log_print(f\"‚Ä¢ Total EventIDs analyzed: {total_eventids_analyzed}\")\n",
    "log_print(f\"‚Ä¢ Total fields analyzed: {total_fields_analyzed}\")\n",
    "log_print(f\"‚Ä¢ Field availability varies significantly by EventID\")\n",
    "log_print(f\"‚Ä¢ Some fields may be conditionally present based on event context\")\n",
    "\n",
    "# End section logging\n",
    "log_print(\"\\n\" + \"-\" * 60 + \" END SECTION \" + \"-\" * 60)\n",
    "log_print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Temporal Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 7: TEMPORAL PATTERN ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "‚è∞ TEMPORAL PATTERN ANALYSIS\n",
      "==================================================\n",
      "üîÑ Extracting temporal data from 200,000 samples...\n",
      "   Processed 50,000 samples...\n",
      "   Processed 100,000 samples...\n",
      "   Processed 150,000 samples...\n",
      "   Processed 200,000 samples...\n",
      "\n",
      "üìÖ TIMESTAMP ANALYSIS:\n",
      "‚Ä¢ @timestamp fields found: 200,000\n",
      "‚Ä¢ UtcTime fields found: 200,000\n",
      "\n",
      "üìä @TIMESTAMP RANGE:\n",
      "‚Ä¢ Earliest: 2025-05-04T11:30:00.040Z\n",
      "‚Ä¢ Latest: 2025-05-04T12:40:00.980Z\n",
      "\n",
      "üìÑ SAMPLE @TIMESTAMPS:\n",
      "    1. 2025-05-04T11:30:00.040Z\n",
      "    2. 2025-05-04T11:35:44.202Z\n",
      "    3. 2025-05-04T11:53:13.689Z\n",
      "    4. 2025-05-04T12:31:13.388Z\n",
      "    5. 2025-05-04T12:34:13.744Z\n",
      "    6. 2025-05-04T12:34:23.261Z\n",
      "    7. 2025-05-04T12:34:23.375Z\n",
      "    8. 2025-05-04T12:34:23.488Z\n",
      "    9. 2025-05-04T12:34:23.584Z\n",
      "   10. 2025-05-04T12:34:56.862Z\n",
      "\n",
      "üìä UTCTIME RANGE:\n",
      "‚Ä¢ Earliest: \n",
      "   2025-05-04 11:30:00.040\n",
      "  \n",
      "‚Ä¢ Latest: \n",
      "   2025-05-04 12:40:00.980\n",
      "  \n",
      "\n",
      "üìÑ SAMPLE UTCTIMES:\n",
      "    1. \n",
      "   2025-05-04 11:30:00.040\n",
      "  \n",
      "    2. \n",
      "   2025-05-04 11:35:44.202\n",
      "  \n",
      "    3. \n",
      "   2025-05-04 11:53:13.689\n",
      "  \n",
      "    4. \n",
      "   2025-05-04 12:31:13.388\n",
      "  \n",
      "    5. \n",
      "   2025-05-04 12:34:13.744\n",
      "  \n",
      "    6. \n",
      "   2025-05-04 12:34:23.261\n",
      "  \n",
      "    7. \n",
      "   2025-05-04 12:34:23.375\n",
      "  \n",
      "    8. \n",
      "   2025-05-04 12:34:23.488\n",
      "  \n",
      "    9. \n",
      "   2025-05-04 12:34:23.584\n",
      "  \n",
      "   10. \n",
      "   2025-05-04 12:34:56.862\n",
      "  \n",
      "\n",
      "------------------------------------------------------------ END SECTION ------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start section logging\n",
    "log_print(\"\\n\" + \"=\" * 80)\n",
    "log_print(\"SECTION 7: TEMPORAL PATTERN ANALYSIS\")\n",
    "log_print(\"=\" * 80)\n",
    "log_print(\"\")\n",
    "\n",
    "log_print(\"‚è∞ TEMPORAL PATTERN ANALYSIS\")\n",
    "log_print(\"=\" * 50)\n",
    "\n",
    "# Analyze timestamps\n",
    "timestamps = []\n",
    "utc_times = []\n",
    "samples_analyzed = 0\n",
    "\n",
    "log_print(f\"üîÑ Extracting temporal data from {len(sample_indices):,} samples...\")\n",
    "\n",
    "with open(TARGET_FILE, 'r') as f:\n",
    "    for line_number, line in enumerate(f):\n",
    "        if line_number in sample_indices:\n",
    "            try:\n",
    "                event = json.loads(line)\n",
    "                samples_analyzed += 1\n",
    "                \n",
    "                # Extract @timestamp\n",
    "                if '@timestamp' in event:\n",
    "                    timestamps.append(event['@timestamp'])\n",
    "                \n",
    "                # Extract UtcTime from XML if available\n",
    "                if 'event' in event and 'original' in event['event']:\n",
    "                    xml_content = event['event']['original']\n",
    "                    event_id, computer, field_count, fields = parse_sysmon_event_basic(xml_content)\n",
    "                    \n",
    "                    if 'UtcTime' in fields and fields['UtcTime']:\n",
    "                        utc_times.append(fields['UtcTime'])\n",
    "                    \n",
    "            except (json.JSONDecodeError, Exception):\n",
    "                continue\n",
    "            \n",
    "            if samples_analyzed % 50000 == 0:\n",
    "                log_print(f\"   Processed {samples_analyzed:,} samples...\")\n",
    "\n",
    "log_print(f\"\\nüìÖ TIMESTAMP ANALYSIS:\")\n",
    "log_print(f\"‚Ä¢ @timestamp fields found: {len(timestamps):,}\")\n",
    "log_print(f\"‚Ä¢ UtcTime fields found: {len(utc_times):,}\")\n",
    "\n",
    "if timestamps:\n",
    "    # Sort timestamps to find range\n",
    "    sorted_timestamps = sorted(timestamps)\n",
    "    log_print(f\"\\nüìä @TIMESTAMP RANGE:\")\n",
    "    log_print(f\"‚Ä¢ Earliest: {sorted_timestamps[0]}\")\n",
    "    log_print(f\"‚Ä¢ Latest: {sorted_timestamps[-1]}\")\n",
    "    \n",
    "    # Sample some timestamps\n",
    "    log_print(f\"\\nüìÑ SAMPLE @TIMESTAMPS:\")\n",
    "    sample_count = min(10, len(sorted_timestamps))\n",
    "    for i in range(sample_count):\n",
    "        idx = i * len(sorted_timestamps) // sample_count\n",
    "        log_print(f\"   {i+1:2d}. {sorted_timestamps[idx]}\")\n",
    "\n",
    "if utc_times:\n",
    "    # Sort UTC times\n",
    "    sorted_utc = sorted(utc_times)\n",
    "    log_print(f\"\\nüìä UTCTIME RANGE:\")\n",
    "    log_print(f\"‚Ä¢ Earliest: {sorted_utc[0]}\")\n",
    "    log_print(f\"‚Ä¢ Latest: {sorted_utc[-1]}\")\n",
    "    \n",
    "    # Sample some UTC times\n",
    "    log_print(f\"\\nüìÑ SAMPLE UTCTIMES:\")\n",
    "    sample_count = min(10, len(sorted_utc))\n",
    "    for i in range(sample_count):\n",
    "        idx = i * len(sorted_utc) // sample_count\n",
    "        log_print(f\"   {i+1:2d}. {sorted_utc[idx]}\")\n",
    "\n",
    "# End section logging\n",
    "log_print(\"\\n\" + \"-\" * 60 + \" END SECTION \" + \"-\" * 60)\n",
    "log_print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sample Event Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 8: SAMPLE EVENT DISPLAY\n",
      "================================================================================\n",
      "\n",
      "üìÑ SAMPLE EVENT DISPLAY\n",
      "==================================================\n",
      "üîç Collecting sample events for EventIDs: [1, 3, 7, 12, 13]\n",
      "\n",
      "üéØ SAMPLE EVENT - EventID 1 (Process Creation)\n",
      "------------------------------------------------------------\n",
      "Computer: \n",
      "   diskjockey.boombox.local\n",
      "  \n",
      "Field Count: 23\n",
      "@timestamp: 2025-05-04T11:30:15.356Z\n",
      "\n",
      "Parsed Fields:\n",
      "   ‚Ä¢ RuleName            : \n",
      "   -\n",
      "  \n",
      "   ‚Ä¢ UtcTime             : \n",
      "   2025-05-04 11:30:15.356\n",
      "  \n",
      "   ‚Ä¢ ProcessGuid         : \n",
      "   {acb80d05-4fc7-6817-5600-000000001600}\n",
      "  \n",
      "   ‚Ä¢ ProcessId           : \n",
      "   4988\n",
      "  \n",
      "   ‚Ä¢ Image               : \n",
      "   C:\\Windows\\System32\\cmd.exe\n",
      "  \n",
      "   ‚Ä¢ FileVersion         : \n",
      "   10.0.17763.1697 (WinBuild.160101.0800)\n",
      "  \n",
      "   ‚Ä¢ Description         : \n",
      "   Windows Command Processor\n",
      "  \n",
      "   ‚Ä¢ Product             : \n",
      "   Microsoft Windows Operating System\n",
      "  \n",
      "   ‚Ä¢ Company             : \n",
      "   Microsoft Corporation\n",
      "  \n",
      "   ‚Ä¢ OriginalFileName    : \n",
      "   Cmd.Exe\n",
      "  \n",
      "   ‚Ä¢ CommandLine         : \n",
      "   C:\\Windows\\system32\\cmd.exe /c C:\\Windows\\system32\\reg.exe query hklm\\software\\microsoft\\windows...\n",
      "   ‚Ä¢ CurrentDirectory    : \n",
      "   C:\\Windows\\system32\\\n",
      "  \n",
      "   ‚Ä¢ User                : \n",
      "   NT AUTHORITY\\SYSTEM\n",
      "  \n",
      "   ‚Ä¢ LogonGuid           : \n",
      "   {acb80d05-4f89-6817-e703-000000000000}\n",
      "  \n",
      "   ‚Ä¢ LogonId             : \n",
      "   0x3e7\n",
      "  \n",
      "   ‚Ä¢ TerminalSessionId   : \n",
      "   0\n",
      "  \n",
      "   ‚Ä¢ IntegrityLevel      : \n",
      "   System\n",
      "  \n",
      "   ‚Ä¢ Hashes              : \n",
      "   SHA256=BC866CFCDDA37E24DC2634DC282C7A0E6F55209DA17A8FA105B07414C0E7C527\n",
      "  \n",
      "   ‚Ä¢ ParentProcessGuid   : \n",
      "   {acb80d05-4fc7-6817-5400-000000001600}\n",
      "  \n",
      "   ‚Ä¢ ParentProcessId     : \n",
      "   4936\n",
      "  \n",
      "   ‚Ä¢ ParentImage         : \n",
      "   C:\\Windows\\System32\\cmd.exe\n",
      "  \n",
      "   ‚Ä¢ ParentCommandLine   : \n",
      "   C:\\Windows\\system32\\cmd.exe /d /c C:\\Windows\\system32\\silcollector.cmd configure\n",
      "  \n",
      "   ‚Ä¢ ParentUser          : \n",
      "   NT AUTHORITY\\SYSTEM\n",
      "  \n",
      "\n",
      "JSON Structure (top-level keys):\n",
      "   ‚Ä¢ agent               : dict\n",
      "   ‚Ä¢ process             : dict\n",
      "   ‚Ä¢ winlog              : dict\n",
      "   ‚Ä¢ log                 : dict\n",
      "   ‚Ä¢ elastic_agent       : dict\n",
      "   ‚Ä¢ message             : str\n",
      "   ‚Ä¢ tags                : list\n",
      "   ‚Ä¢ input               : dict\n",
      "   ‚Ä¢ @timestamp          : str\n",
      "   ‚Ä¢ ecs                 : dict\n",
      "   ‚Ä¢ related             : dict\n",
      "   ‚Ä¢ data_stream         : dict\n",
      "   ‚Ä¢ host                : dict\n",
      "   ‚Ä¢ event               : dict\n",
      "   ‚Ä¢ user                : dict\n",
      "\n",
      "üéØ SAMPLE EVENT - EventID 3 (Network Connection)\n",
      "------------------------------------------------------------\n",
      "Computer: \n",
      "   diskjockey.boombox.local\n",
      "  \n",
      "Field Count: 18\n",
      "@timestamp: 2025-05-04T11:30:01.045Z\n",
      "\n",
      "Parsed Fields:\n",
      "   ‚Ä¢ RuleName            : \n",
      "   -\n",
      "  \n",
      "   ‚Ä¢ UtcTime             : \n",
      "   2025-05-04 11:30:01.045\n",
      "  \n",
      "   ‚Ä¢ ProcessGuid         : \n",
      "   {acb80d05-4f9d-6817-3400-000000001600}\n",
      "  \n",
      "   ‚Ä¢ ProcessId           : \n",
      "   2608\n",
      "  \n",
      "   ‚Ä¢ Image               : \n",
      "   C:\\Windows\\System32\\dns.exe\n",
      "  \n",
      "   ‚Ä¢ User                : \n",
      "   NT AUTHORITY\\SYSTEM\n",
      "  \n",
      "   ‚Ä¢ Protocol            : \n",
      "   udp\n",
      "  \n",
      "   ‚Ä¢ Initiated           : \n",
      "   false\n",
      "  \n",
      "   ‚Ä¢ SourceIsIpv6        : \n",
      "   false\n",
      "  \n",
      "   ‚Ä¢ SourceIp            : \n",
      "   10.1.0.4\n",
      "  \n",
      "   ‚Ä¢ SourceHostname      : \n",
      "   diskjockey.boombox.local\n",
      "  \n",
      "   ‚Ä¢ SourcePort          : \n",
      "   53\n",
      "  \n",
      "   ‚Ä¢ SourcePortName      : \n",
      "   domain\n",
      "  \n",
      "   ‚Ä¢ DestinationIsIpv6   : \n",
      "   false\n",
      "  \n",
      "   ‚Ä¢ DestinationIp       : \n",
      "   10.1.0.4\n",
      "  \n",
      "   ‚Ä¢ DestinationHostname : \n",
      "   diskjockey.boombox.local\n",
      "  \n",
      "   ‚Ä¢ DestinationPort     : \n",
      "   53509\n",
      "  \n",
      "   ‚Ä¢ DestinationPortName : \n",
      "   -\n",
      "  \n",
      "\n",
      "JSON Structure (top-level keys):\n",
      "   ‚Ä¢ agent               : dict\n",
      "   ‚Ä¢ process             : dict\n",
      "   ‚Ä¢ winlog              : dict\n",
      "   ‚Ä¢ log                 : dict\n",
      "   ‚Ä¢ elastic_agent       : dict\n",
      "   ‚Ä¢ destination         : dict\n",
      "   ‚Ä¢ source              : dict\n",
      "   ‚Ä¢ message             : str\n",
      "   ‚Ä¢ tags                : list\n",
      "   ‚Ä¢ network             : dict\n",
      "   ‚Ä¢ input               : dict\n",
      "   ‚Ä¢ @timestamp          : str\n",
      "   ‚Ä¢ ecs                 : dict\n",
      "   ‚Ä¢ related             : dict\n",
      "   ‚Ä¢ data_stream         : dict\n",
      "   ‚Ä¢ host                : dict\n",
      "   ‚Ä¢ event               : dict\n",
      "   ‚Ä¢ user                : dict\n",
      "\n",
      "üéØ SAMPLE EVENT - EventID 7 (Image/Library Loaded)\n",
      "------------------------------------------------------------\n",
      "Computer: \n",
      "   diskjockey.boombox.local\n",
      "  \n",
      "Field Count: 16\n",
      "@timestamp: 2025-05-04T11:30:05.473Z\n",
      "\n",
      "Parsed Fields:\n",
      "   ‚Ä¢ RuleName            : \n",
      "   -\n",
      "  \n",
      "   ‚Ä¢ UtcTime             : \n",
      "   2025-05-04 11:30:05.473\n",
      "  \n",
      "   ‚Ä¢ ProcessGuid         : \n",
      "   {acb80d05-4f9d-6817-3a00-000000001600}\n",
      "  \n",
      "   ‚Ä¢ ProcessId           : \n",
      "   2976\n",
      "  \n",
      "   ‚Ä¢ Image               : \n",
      "   C:\\Windows\\System32\\sppsvc.exe\n",
      "  \n",
      "   ‚Ä¢ ImageLoaded         : \n",
      "   C:\\Windows\\System32\\clbcatq.dll\n",
      "  \n",
      "   ‚Ä¢ FileVersion         : \n",
      "   2001.12.10941.16384 (WinBuild.160101.0800)\n",
      "  \n",
      "   ‚Ä¢ Description         : \n",
      "   COM+ Configuration Catalog\n",
      "  \n",
      "   ‚Ä¢ Product             : \n",
      "   Microsoft Windows Operating System\n",
      "  \n",
      "   ‚Ä¢ Company             : \n",
      "   Microsoft Corporation\n",
      "  \n",
      "   ‚Ä¢ OriginalFileName    : \n",
      "   CLBCATQ.DLL\n",
      "  \n",
      "   ‚Ä¢ Hashes              : \n",
      "   SHA256=2D7E8C878F2B200159279CAC7F1FDDCA15B2C18E03EC9510823559C4716DD1BA\n",
      "  \n",
      "   ‚Ä¢ Signed              : \n",
      "   true\n",
      "  \n",
      "   ‚Ä¢ Signature           : \n",
      "   Microsoft Windows\n",
      "  \n",
      "   ‚Ä¢ SignatureStatus     : \n",
      "   Valid\n",
      "  \n",
      "   ‚Ä¢ User                : \n",
      "   NT AUTHORITY\\NETWORK SERVICE\n",
      "  \n",
      "\n",
      "JSON Structure (top-level keys):\n",
      "   ‚Ä¢ agent               : dict\n",
      "   ‚Ä¢ process             : dict\n",
      "   ‚Ä¢ winlog              : dict\n",
      "   ‚Ä¢ log                 : dict\n",
      "   ‚Ä¢ elastic_agent       : dict\n",
      "   ‚Ä¢ message             : str\n",
      "   ‚Ä¢ tags                : list\n",
      "   ‚Ä¢ input               : dict\n",
      "   ‚Ä¢ @timestamp          : str\n",
      "   ‚Ä¢ file                : dict\n",
      "   ‚Ä¢ ecs                 : dict\n",
      "   ‚Ä¢ related             : dict\n",
      "   ‚Ä¢ data_stream         : dict\n",
      "   ‚Ä¢ host                : dict\n",
      "   ‚Ä¢ event               : dict\n",
      "   ‚Ä¢ user                : dict\n",
      "\n",
      "üéØ SAMPLE EVENT - EventID 12 (Registry Event (Object create/delete))\n",
      "------------------------------------------------------------\n",
      "Computer: \n",
      "   diskjockey.boombox.local\n",
      "  \n",
      "Field Count: 8\n",
      "@timestamp: 2025-05-04T11:30:05.479Z\n",
      "\n",
      "Parsed Fields:\n",
      "   ‚Ä¢ RuleName            : \n",
      "   -\n",
      "  \n",
      "   ‚Ä¢ EventType           : \n",
      "   CreateKey\n",
      "  \n",
      "   ‚Ä¢ UtcTime             : \n",
      "   2025-05-04 11:30:05.479\n",
      "  \n",
      "   ‚Ä¢ ProcessGuid         : \n",
      "   {acb80d05-4f9d-6817-3800-000000001600}\n",
      "  \n",
      "   ‚Ä¢ ProcessId           : \n",
      "   2716\n",
      "  \n",
      "   ‚Ä¢ Image               : \n",
      "   C:\\Windows\\Sysmon64.exe\n",
      "  \n",
      "   ‚Ä¢ TargetObject        : \n",
      "   HKU\\.DEFAULT\\Software\\Microsoft\\SystemCertificates\\Disallowed\\Certificates\n",
      "  \n",
      "   ‚Ä¢ User                : \n",
      "   NT AUTHORITY\\SYSTEM\n",
      "  \n",
      "\n",
      "JSON Structure (top-level keys):\n",
      "   ‚Ä¢ registry            : dict\n",
      "   ‚Ä¢ agent               : dict\n",
      "   ‚Ä¢ process             : dict\n",
      "   ‚Ä¢ winlog              : dict\n",
      "   ‚Ä¢ log                 : dict\n",
      "   ‚Ä¢ elastic_agent       : dict\n",
      "   ‚Ä¢ message             : str\n",
      "   ‚Ä¢ tags                : list\n",
      "   ‚Ä¢ input               : dict\n",
      "   ‚Ä¢ @timestamp          : str\n",
      "   ‚Ä¢ ecs                 : dict\n",
      "   ‚Ä¢ related             : dict\n",
      "   ‚Ä¢ data_stream         : dict\n",
      "   ‚Ä¢ host                : dict\n",
      "   ‚Ä¢ event               : dict\n",
      "   ‚Ä¢ user                : dict\n",
      "\n",
      "üéØ SAMPLE EVENT - EventID 13 (Registry Event (Value Set))\n",
      "------------------------------------------------------------\n",
      "Computer: \n",
      "   diskjockey.boombox.local\n",
      "  \n",
      "Field Count: 9\n",
      "@timestamp: 2025-05-04T11:30:05.479Z\n",
      "\n",
      "Parsed Fields:\n",
      "   ‚Ä¢ RuleName            : \n",
      "   -\n",
      "  \n",
      "   ‚Ä¢ EventType           : \n",
      "   SetValue\n",
      "  \n",
      "   ‚Ä¢ UtcTime             : \n",
      "   2025-05-04 11:30:05.479\n",
      "  \n",
      "   ‚Ä¢ ProcessGuid         : \n",
      "   {acb80d05-4f8b-6817-1200-000000001600}\n",
      "  \n",
      "   ‚Ä¢ ProcessId           : \n",
      "   68\n",
      "  \n",
      "   ‚Ä¢ Image               : \n",
      "   C:\\Windows\\system32\\svchost.exe\n",
      "  \n",
      "   ‚Ä¢ TargetObject        : \n",
      "   HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Schedule\\TaskCache\\Tasks\\{60EE6C7E-6FED-4BBB-B...\n",
      "   ‚Ä¢ Details             : \n",
      "   Binary Data\n",
      "  \n",
      "   ‚Ä¢ User                : \n",
      "   NT AUTHORITY\\SYSTEM\n",
      "  \n",
      "\n",
      "JSON Structure (top-level keys):\n",
      "   ‚Ä¢ registry            : dict\n",
      "   ‚Ä¢ agent               : dict\n",
      "   ‚Ä¢ process             : dict\n",
      "   ‚Ä¢ winlog              : dict\n",
      "   ‚Ä¢ log                 : dict\n",
      "   ‚Ä¢ elastic_agent       : dict\n",
      "   ‚Ä¢ message             : str\n",
      "   ‚Ä¢ tags                : list\n",
      "   ‚Ä¢ input               : dict\n",
      "   ‚Ä¢ @timestamp          : str\n",
      "   ‚Ä¢ ecs                 : dict\n",
      "   ‚Ä¢ related             : dict\n",
      "   ‚Ä¢ data_stream         : dict\n",
      "   ‚Ä¢ host                : dict\n",
      "   ‚Ä¢ event               : dict\n",
      "   ‚Ä¢ user                : dict\n",
      "\n",
      "------------------------------------------------------------ END SECTION ------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start section logging\n",
    "log_print(\"\\n\" + \"=\" * 80)\n",
    "log_print(\"SECTION 8: SAMPLE EVENT DISPLAY\")\n",
    "log_print(\"=\" * 80)\n",
    "log_print(\"\")\n",
    "\n",
    "log_print(\"üìÑ SAMPLE EVENT DISPLAY\")\n",
    "log_print(\"=\" * 50)\n",
    "\n",
    "# Display sample events for different EventIDs\n",
    "sample_events = {}\n",
    "target_eventids = [1, 3, 7, 12, 13]  # Key Sysmon events to showcase\n",
    "\n",
    "log_print(f\"üîç Collecting sample events for EventIDs: {target_eventids}\")\n",
    "\n",
    "with open(TARGET_FILE, 'r') as f:\n",
    "    for line_number, line in enumerate(f):\n",
    "        if line_number in sample_indices and len(sample_events) < len(target_eventids):\n",
    "            try:\n",
    "                event = json.loads(line)\n",
    "                if 'event' in event and 'original' in event['event']:\n",
    "                    xml_content = event['event']['original']\n",
    "                    event_id, computer, field_count, fields = parse_sysmon_event_basic(xml_content)\n",
    "                    \n",
    "                    if event_id in target_eventids and event_id not in sample_events:\n",
    "                        sample_events[event_id] = {\n",
    "                            'full_event': event,\n",
    "                            'parsed_fields': fields,\n",
    "                            'computer': computer,\n",
    "                            'field_count': field_count\n",
    "                        }\n",
    "                        \n",
    "            except (json.JSONDecodeError, Exception):\n",
    "                continue\n",
    "\n",
    "# Display samples\n",
    "for event_id in sorted(sample_events.keys()):\n",
    "    sample = sample_events[event_id]\n",
    "    description = eventid_descriptions.get(event_id, \"Unknown\")\n",
    "    \n",
    "    log_print(f\"\\nüéØ SAMPLE EVENT - EventID {event_id} ({description})\")\n",
    "    log_print(\"-\" * 60)\n",
    "    log_print(f\"Computer: {sample['computer']}\")\n",
    "    log_print(f\"Field Count: {sample['field_count']}\")\n",
    "    log_print(f\"@timestamp: {sample['full_event'].get('@timestamp', 'N/A')}\")\n",
    "    \n",
    "    log_print(f\"\\nParsed Fields:\")\n",
    "    for field_name, field_value in sample['parsed_fields'].items():\n",
    "        # Truncate long values for readability\n",
    "        display_value = str(field_value)[:100] + \"...\" if field_value and len(str(field_value)) > 100 else field_value\n",
    "        log_print(f\"   ‚Ä¢ {field_name:20s}: {display_value}\")\n",
    "    \n",
    "    log_print(f\"\\nJSON Structure (top-level keys):\")\n",
    "    for key in sample['full_event'].keys():\n",
    "        value_type = type(sample['full_event'][key]).__name__\n",
    "        log_print(f\"   ‚Ä¢ {key:20s}: {value_type}\")\n",
    "\n",
    "# End section logging\n",
    "log_print(\"\\n\" + \"-\" * 60 + \" END SECTION \" + \"-\" * 60)\n",
    "log_print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analysis Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 9: ANALYSIS SUMMARY AND RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "üìä ANALYSIS SUMMARY AND RECOMMENDATIONS\n",
      "============================================================\n",
      "üîç DATASET CHARACTERISTICS:\n",
      "   ‚Ä¢ Total records in file: ~570,078\n",
      "   ‚Ä¢ Samples analyzed: 200,000\n",
      "   ‚Ä¢ XML parsing success rate: 100.0%\n",
      "   ‚Ä¢ Unique EventIDs found: 17\n",
      "   ‚Ä¢ Most common EventID: 12 (101,377 occurrences)\n",
      "   ‚Ä¢ Unique computers: 4\n",
      "\n",
      "üí° PROCESSING RECOMMENDATIONS:\n",
      "   üß† Memory Management:\n",
      "      - Use batch processing for large dataset (570,078 records)\n",
      "      - Consider chunked reading for memory efficiency\n",
      "      - Implement progress tracking for long operations\n",
      "   üõ†Ô∏è  XML Processing:\n",
      "      - XML sanitization is crucial for 0 problematic records\n",
      "      - BeautifulSoup XML parser handles malformed XML well\n",
      "      - Namespace handling required for proper field extraction\n",
      "   üìä EventID-Specific Handling:\n",
      "      - Different EventIDs have different field schemas\n",
      "      - Field availability varies significantly by EventID\n",
      "      - Consider separate processing pipelines per EventID\n",
      "   üìÑ CSV Conversion Strategy:\n",
      "      - Use EventID-specific field mappings from schema analysis\n",
      "      - Handle missing fields with appropriate default values\n",
      "      - Implement robust error logging for malformed XML\n",
      "      - Consider unified vs EventID-specific CSV outputs\n",
      "\n",
      "‚úÖ NEXT STEPS:\n",
      "   1. Review findings above\n",
      "   2. Update notebook #2 with optimized processing logic\n",
      "   3. Implement EventID-specific field validation\n",
      "   4. Add comprehensive error handling and logging\n",
      "   5. Test with full dataset after validation\n",
      "\n",
      "üéØ Ready to proceed to notebook #2 optimization!\n",
      "\n",
      "------------------------------------------------------------ END SECTION ------------------------------------------------------------\n",
      "\n",
      "\n",
      "üìã Analysis complete! Results saved to: outputs/2a-sysmon/2a-sysmon_exploratory_analysis_20250629_112356.log\n",
      "üìÅ Output directory: outputs/2a-sysmon\n",
      "üéâ Sysmon exploratory analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Start section logging\n",
    "log_print(\"\\n\" + \"=\" * 80)\n",
    "log_print(\"SECTION 9: ANALYSIS SUMMARY AND RECOMMENDATIONS\")\n",
    "log_print(\"=\" * 80)\n",
    "log_print(\"\")\n",
    "\n",
    "log_print(\"üìä ANALYSIS SUMMARY AND RECOMMENDATIONS\")\n",
    "log_print(\"=\" * 60)\n",
    "\n",
    "# Calculate summary statistics\n",
    "total_eventids_found = len(eventid_counts)\n",
    "most_common_eventid = eventid_counts.most_common(1)[0] if eventid_counts else (None, 0)\n",
    "parsing_success_rate = (parsing_success / samples_processed) * 100 if samples_processed > 0 else 0\n",
    "\n",
    "log_print(f\"üîç DATASET CHARACTERISTICS:\")\n",
    "log_print(f\"   ‚Ä¢ Total records in file: ~{total_records:,}\")\n",
    "log_print(f\"   ‚Ä¢ Samples analyzed: {samples_processed:,}\")\n",
    "log_print(f\"   ‚Ä¢ XML parsing success rate: {parsing_success_rate:.1f}%\")\n",
    "log_print(f\"   ‚Ä¢ Unique EventIDs found: {total_eventids_found}\")\n",
    "log_print(f\"   ‚Ä¢ Most common EventID: {most_common_eventid[0]} ({most_common_eventid[1]:,} occurrences)\")\n",
    "log_print(f\"   ‚Ä¢ Unique computers: {len(computer_counts)}\")\n",
    "\n",
    "log_print(f\"\\nüí° PROCESSING RECOMMENDATIONS:\")\n",
    "log_print(f\"   üß† Memory Management:\")\n",
    "log_print(f\"      - Use batch processing for large dataset ({total_records:,} records)\")\n",
    "log_print(f\"      - Consider chunked reading for memory efficiency\")\n",
    "log_print(f\"      - Implement progress tracking for long operations\")\n",
    "\n",
    "log_print(f\"   üõ†Ô∏è  XML Processing:\")\n",
    "log_print(f\"      - XML sanitization is crucial for {parsing_errors:,} problematic records\")\n",
    "log_print(f\"      - BeautifulSoup XML parser handles malformed XML well\")\n",
    "log_print(f\"      - Namespace handling required for proper field extraction\")\n",
    "\n",
    "log_print(f\"   üìä EventID-Specific Handling:\")\n",
    "log_print(f\"      - Different EventIDs have different field schemas\")\n",
    "log_print(f\"      - Field availability varies significantly by EventID\")\n",
    "log_print(f\"      - Consider separate processing pipelines per EventID\")\n",
    "\n",
    "log_print(f\"   üìÑ CSV Conversion Strategy:\")\n",
    "log_print(f\"      - Use EventID-specific field mappings from schema analysis\")\n",
    "log_print(f\"      - Handle missing fields with appropriate default values\")\n",
    "log_print(f\"      - Implement robust error logging for malformed XML\")\n",
    "log_print(f\"      - Consider unified vs EventID-specific CSV outputs\")\n",
    "\n",
    "log_print(f\"\\n‚úÖ NEXT STEPS:\")\n",
    "log_print(f\"   1. Review findings above\")\n",
    "log_print(f\"   2. Update notebook #2 with optimized processing logic\")\n",
    "log_print(f\"   3. Implement EventID-specific field validation\")\n",
    "log_print(f\"   4. Add comprehensive error handling and logging\")\n",
    "log_print(f\"   5. Test with full dataset after validation\")\n",
    "\n",
    "log_print(f\"\\nüéØ Ready to proceed to notebook #2 optimization!\")\n",
    "\n",
    "# End section logging\n",
    "log_print(\"\\n\" + \"-\" * 60 + \" END SECTION \" + \"-\" * 60)\n",
    "log_print(\"\")\n",
    "\n",
    "print(f\"\\nüìã Analysis complete! Results saved to: {log_filename}\")\n",
    "print(f\"üìÅ Output directory: {analysis_outputs_dir}\")\n",
    "print(f\"üéâ Sysmon exploratory analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
