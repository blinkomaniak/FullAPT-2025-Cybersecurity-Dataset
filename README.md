# Advanced Cybersecurity Research Platform

A comprehensive, dual-purpose cybersecurity research platform combining **APT attack simulation analysis** and **machine learning-based anomaly detection**. This platform enables advanced threat analysis through both real-time attack correlation and large-scale ML model evaluation across multiple cybersecurity datasets.

## üèóÔ∏è Platform Architecture

This research platform consists of two integrated but distinct systems:

### 1. **APT Attack Analysis Pipeline** (`data-raw/`)
Real-time APT simulation analysis with Windows Sysmon, network traffic, and Caldera attack correlation.

### 2. **ML Anomaly Detection Framework** (`analysis/`)
Multi-model machine learning pipeline for cybersecurity dataset evaluation using SAE, LSTM-SAE, GRU-SAE, and Isolation Forest.

## üìÇ Complete Directory Structure

```
research/                                    # Platform root directory
‚îú‚îÄ‚îÄ üéØ data-raw/                             # APT ATTACK ANALYSIS SYSTEM
‚îÇ   ‚îú‚îÄ‚îÄ scripts/                             # APT processing pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline/                        # Core processing scripts (#1-#6)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1_elastic_index_downloader.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2_sysmon_csv_creator.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 3_network_traffic_csv_creator.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 4_universal_caldera_report_transformer.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 5_sysmon_event_analysis.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 6_simple_timeline_plotter.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ batch/                           # Automated batch processing
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unified_jsonl_processor.sh
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enhanced_caldera_batch_processor.sh
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sysmon_batch_processor.sh
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ network_batch_processor.sh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analysis/                        # Analysis and utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/                          # APT configuration files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dev/                             # Development notebooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exploratory/                     # Data exploration notebooks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools/                           # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ apt-1/ to apt-6/                     # APT simulation runs (50 total)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ apt-X-run-XX/                    # Individual simulation data
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config.yaml                  # Run configuration
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ entry_config.csv             # Entry mapping
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ *event-logs.json             # Original Caldera reports
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ *extracted_information.json  # Processed Caldera reports
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sysmon-run-XX.csv            # Windows event logs
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ network_traffic_flow-run-XX.csv # Network flow data
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ *.jsonl                      # Raw Elasticsearch data
‚îÇ   ‚îú‚îÄ‚îÄ issues/                              # Known issues and solutions
‚îÇ   ‚îú‚îÄ‚îÄ dataset-backup/                      # Compressed backups
‚îÇ   ‚îî‚îÄ‚îÄ README.md                            # APT pipeline documentation
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ analysis/                             # ML ANOMALY DETECTION FRAMEWORK
‚îÇ   ‚îú‚îÄ‚îÄ sae/                                 # Stacked Autoencoder pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01-aggregation.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02-encoding-bigbase-sae.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03-training-sae.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04-model-evaluation-sae.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05-result-vis.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_sae_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ lstm-sae/                            # LSTM Autoencoder pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01-aggregation.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02-encoding-lstm-sae.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03-training-lstm-sae.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04-model-evaluation-lstm-sae.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05-result-vis-lstm-sae.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_lstm_sae_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ gru-sae/                             # GRU Autoencoder pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01-aggregation.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02-encoding-gru-sae.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03-training-gru-sae.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04-model-evaluation-gru-sae.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05-result-vis-gru-sae.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_gru_sae_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ iforest/                             # Isolation Forest pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01-aggregation.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02-encoding-bigbase-iforest.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03-training-iforest.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04-model-evaluation-iforest.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05-feature-space-iforest.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_iforest_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ config/                              # ML configuration files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schema-{dataset}-{model}-v{X}.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ encoding-{dataset}-{model}-v{X}.json
‚îÇ   ‚îú‚îÄ‚îÄ comparative-evaluation/              # Cross-model analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ comparative_analysis.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset_quality_analyzer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ roc_comparison_generator.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/                               # Shared utilities
‚îÇ       ‚îú‚îÄ‚îÄ paths.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py
‚îÇ       ‚îî‚îÄ‚îÄ encoding.py
‚îÇ
‚îú‚îÄ‚îÄ üìä datasets/                             # RAW CYBERSECURITY DATASETS
‚îÇ   ‚îú‚îÄ‚îÄ bigbase/                             # Windows Event Logs (50 CSV files)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset-01.csv to dataset-50.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reports/                         # Caldera attack reports
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ cal-report-01.json to cal-report-50.json
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ entry_params-01.json to entry_params-50.json
‚îÇ   ‚îú‚îÄ‚îÄ unraveled/                           # Multi-modal cybersecurity data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ host-logs/                       # Host-based logs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audit/                       # Linux audit logs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth/                        # Authentication logs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ filebeat/                    # Filebeat logs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ syslog/                      # System logs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ windows/                     # Windows event logs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ network-flows/                   # Network flow data by weeks/days
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Week1_Day1-2_05262021-05272021/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Week1_Day3_05282021/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ... (26 week/day directories)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Week6_Day6-7_07032021-07042021/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nids/                            # Network intrusion detection
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ all_snort
‚îÇ   ‚îî‚îÄ‚îÄ dapt2020/                            # DAPT2020 network flow dataset
‚îÇ       ‚îú‚îÄ‚îÄ README.md
‚îÇ       ‚îú‚îÄ‚îÄ enp0s3-*.pcap_Flow.csv          # Network flow files
‚îÇ       ‚îî‚îÄ‚îÄ util.py
‚îÇ
‚îú‚îÄ‚îÄ üíæ data/                                 # PROCESSED PIPELINE OUTPUTS
‚îÇ   ‚îú‚îÄ‚îÄ processed/                           # Stage 1: Aggregated datasets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {model}-{dataset}-v{X}.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata/
‚îÇ   ‚îî‚îÄ‚îÄ encoded/                             # Stage 2: Encoded features
‚îÇ       ‚îî‚îÄ‚îÄ {model}-{dataset}-v{X}/
‚îÇ           ‚îú‚îÄ‚îÄ X_train_encoded.npz
‚îÇ           ‚îú‚îÄ‚îÄ X_test_encoded.npz
‚îÇ           ‚îú‚îÄ‚îÄ y_train.npy
‚îÇ           ‚îî‚îÄ‚îÄ column_transformer.joblib
‚îÇ
‚îú‚îÄ‚îÄ üéØ models/                               # TRAINED ML MODELS
‚îÇ   ‚îî‚îÄ‚îÄ {model}-{dataset}-v{X}/
‚îÇ       ‚îú‚îÄ‚îÄ model.keras                      # Neural network models
‚îÇ       ‚îú‚îÄ‚îÄ model.joblib                     # Scikit-learn models
‚îÇ       ‚îî‚îÄ‚îÄ training_history.json
‚îÇ
‚îú‚îÄ‚îÄ üìà artifacts/                            # ANALYSIS OUTPUTS
‚îÇ   ‚îú‚îÄ‚îÄ eval/                                # Model evaluation results
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {model}-{dataset}-v{X}/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation_report.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ roc_curve.png
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ confusion_matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ plots/                               # Visualizations
‚îÇ   ‚îú‚îÄ‚îÄ metadata/                            # Dataset metadata
‚îÇ   ‚îú‚îÄ‚îÄ comparative/                         # Cross-model comparisons
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ comparative_analysis_report.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_performance_comparison.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_set_impact_analysis.png
‚îÇ   ‚îú‚îÄ‚îÄ quality_analysis/                    # Dataset quality reports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quality_analysis_report.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_quality_analysis.png
‚îÇ   ‚îî‚îÄ‚îÄ roc_comparison/                      # ROC curve comparisons
‚îÇ       ‚îî‚îÄ‚îÄ roc_pr_comparison_{dataset}_v{X}.png
‚îÇ
‚îú‚îÄ‚îÄ üìö docs/                                 # DOCUMENTATION
‚îÇ   ‚îú‚îÄ‚îÄ ACADEMIC-PAPER-GUIDELINES-BIGBASE.md
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure.yaml
‚îÇ
‚îú‚îÄ‚îÄ üìÑ pdfs/                                 # RESEARCH PAPERS
‚îÇ   ‚îî‚îÄ‚îÄ [100+ cybersecurity research papers]
‚îÇ
‚îú‚îÄ‚îÄ üîß others/                               # MISCELLANEOUS FILES
‚îÇ   ‚îú‚îÄ‚îÄ elasticsearch_certs/                # Elasticsearch certificates
‚îÇ   ‚îú‚îÄ‚îÄ hacking-scripts/                     # Attack simulation scripts
‚îÇ   ‚îú‚îÄ‚îÄ images/                              # Network diagrams and visualizations
‚îÇ   ‚îú‚îÄ‚îÄ papers/                              # Additional research papers
‚îÇ   ‚îî‚îÄ‚îÄ setup-windows-shared-files/         # Windows setup files
‚îÇ
‚îú‚îÄ‚îÄ üêç dataset-venv/                         # PYTHON VIRTUAL ENVIRONMENT
‚îú‚îÄ‚îÄ CLAUDE.md                                # Claude Code documentation
‚îî‚îÄ‚îÄ README.md                                # This file
```

## üéØ **APT Attack Analysis System** (`data-raw/`)

### Overview
Real-time analysis pipeline for Advanced Persistent Threat simulations with 50 comprehensive attack runs across 6 APT campaigns. Correlates Windows Sysmon events, network traffic flows, and Caldera attack simulation data.

### Key Capabilities
- **Multi-modal Data Processing**: Windows events, network flows, attack logs
- **Real-time Correlation**: 90-95% success rate in correlating attack events with system telemetry
- **Automated Processing**: Batch processors for large-scale analysis
- **Interactive Analysis**: Individual event tracking and visualization

### Core Pipeline Scripts
1. **Script #1**: Elasticsearch data downloader with secure authentication
2. **Script #2**: Sysmon JSONL to CSV converter (18+ event types)
3. **Script #3**: Network traffic JSONL to CSV converter (42 mapped fields)
4. **Script #4**: Universal Caldera report transformer (7 transformation functions)
5. **Script #5**: Main correlation engine with time-window analysis
6. **Script #6**: Timeline visualization generator

### Dataset Scope
- **50 APT Simulation Runs**: apt-1-run-01 through apt-6-run-50
- **6 APT Campaigns**: Different attack patterns and techniques
- **Multi-gigabyte Scale**: 1-5GB raw data per run
- **High Success Rate**: 90-95% event correlation accuracy

### Usage Example
```bash
cd data-raw/scripts/batch
./unified_jsonl_processor.sh              # Process all JSONL files
./enhanced_caldera_batch_processor.sh     # Process all Caldera reports
./sysmon_batch_processor.sh               # Run correlation analysis
```

## ü§ñ **ML Anomaly Detection Framework** (`analysis/`)

### Overview
Comprehensive machine learning pipeline for cybersecurity anomaly detection using multiple model architectures. Supports benign-only training for unsupervised anomaly detection across three major cybersecurity datasets.

### Supported Models
- **SAE**: Stacked Autoencoder with bottleneck architecture
- **LSTM-SAE**: LSTM-based Autoencoder for temporal patterns
- **GRU-SAE**: GRU-based Autoencoder (more efficient than LSTM)
- **Isolation Forest**: Ensemble-based anomaly detection with PCA

### Pipeline Stages
1. **Stage 01**: Data aggregation with schema-based processing
2. **Stage 02**: Feature encoding (TF-IDF, OneHot, StandardScaler)
3. **Stage 03**: Model training on benign data only
4. **Stage 04**: Evaluation with ROC-AUC, precision, recall metrics
5. **Stage 05**: Result visualization and analysis

### Datasets
- **bigbase**: 50 Windows event log CSV files with TF-IDF text processing
- **unraveled**: Multi-modal data (host logs, network flows, NIDS)
- **dapt2020**: Pre-processed network flows with 85 CICFlowMeter features

### Usage Examples
```bash
# SAE Pipeline
cd analysis/sae
python run_sae_pipeline.py --dataset bigbase --version v1

# LSTM-SAE Pipeline
cd analysis/lstm-sae  
python run_lstm_sae_pipeline.py --dataset unraveled --version v1 --seq-len 10

# Comparative Analysis
cd analysis/comparative-evaluation
python comparative_analysis.py
```

## üìä **Integrated Research Capabilities**

### Cross-System Analysis
The platform enables unique research opportunities by combining:
- **APT Attack Patterns** from real simulation data
- **ML Model Performance** on large-scale cybersecurity datasets
- **Multi-modal Data Fusion** across different data types
- **Temporal Analysis** of attack progression and system response

### Research Applications
1. **Attack Detection Evaluation**: Test ML models against real APT simulation data
2. **Feature Engineering**: Extract features from APT data for ML training
3. **Temporal Pattern Analysis**: Use LSTM/GRU models on APT time-series data
4. **Cross-Dataset Validation**: Validate models across different cybersecurity datasets
5. **Anomaly Detection**: Apply trained models to detect novel attack patterns

## üöÄ **Quick Start Guide**

### Prerequisites
```bash
# Activate Python environment
source dataset-venv/bin/activate

# Verify dependencies
python -c "import pandas, numpy, tensorflow, sklearn, matplotlib"
```

### APT Analysis Quick Start
```bash
# Navigate to APT system
cd data-raw/scripts/pipeline

# Process a single APT run
python 2_sysmon_csv_creator.py --apt-dir ../../apt-6/apt-6-run-50
python 3_network_traffic_csv_creator.py --apt-dir ../../apt-6/apt-6-run-50
python 4_universal_caldera_report_transformer.py --apt-dir ../../apt-6/apt-6-run-50
python 5_sysmon_event_analysis.py --apt-dir ../../apt-6/apt-6-run-50
```

### ML Framework Quick Start
```bash
# Navigate to ML framework
cd analysis/sae

# Run complete SAE pipeline
python run_sae_pipeline.py --dataset bigbase --version v1

# Compare multiple models
cd ../comparative-evaluation
python comparative_analysis.py
```

## üîß **System Requirements**

### Hardware Recommendations
- **RAM**: 16GB+ recommended (32GB for large datasets)
- **Storage**: 50-100GB free space for datasets and outputs
- **CPU**: Multi-core processor (8+ cores recommended)
- **GPU**: Optional but recommended for LSTM/GRU training

### Software Dependencies
```bash
# Core ML packages
tensorflow>=2.19.0
torch>=2.7.1
scikit-learn>=1.6.1
pandas>=2.2.3
numpy>=1.24.0

# APT analysis packages
beautifulsoup4
elasticsearch
pyyaml
matplotlib
seaborn

# Optional packages
jupyter
notebook
```

## üìà **Performance Metrics**

### APT Analysis Performance
- **Event Correlation**: 90-95% success rate
- **Processing Speed**: 15-60 minutes per APT run
- **Data Volume**: 500K+ Sysmon events, 1M+ network flows per run
- **Batch Processing**: 50 runs in 3-5 hours

### ML Framework Performance
- **Model Training**: 10-60 minutes depending on model and dataset
- **Memory Efficiency**: Optimized for large datasets with sparse matrices
- **Evaluation Speed**: Comprehensive evaluation in 5-15 minutes
- **Cross-Model Comparison**: Complete analysis in 30-60 minutes

## üìù **Research Documentation**

### Academic Resources
- **100+ Research Papers**: Latest cybersecurity and ML papers in `pdfs/`
- **Academic Guidelines**: Paper writing guidelines in `docs/`
- **Experimental Design**: Detailed documentation for each model pipeline

### Technical Documentation
- **APT Pipeline**: Complete documentation in `data-raw/scripts/README.md`
- **ML Framework**: Individual documentation for each model pipeline
- **Configuration**: Schema and encoding configuration examples
- **Troubleshooting**: Common issues and solutions

## ü§ù **Contributing and Usage**

### Research Ethics
- This platform is designed for **defensive cybersecurity research** only
- Attack simulation data is for **threat detection improvement**
- No malicious tools or techniques are included

### Best Practices
1. **Data Integrity**: Always backup data before processing
2. **Resource Management**: Monitor memory usage during large operations
3. **Reproducibility**: Use version-controlled configurations
4. **Documentation**: Document experimental changes and results

### Contributing Guidelines
- Follow existing code style and structure
- Add comprehensive error handling and logging
- Update documentation for new features
- Include validation and testing capabilities

## üìä **Research Impact**

This platform enables cutting-edge research in:
- **Advanced Threat Detection** using ML-based approaches
- **Multi-modal Cybersecurity Analytics** across different data types
- **Temporal Attack Pattern Analysis** with sequence-based models
- **Cross-Dataset Validation** for robust model evaluation
- **Real-time Security Operations** with automated correlation

**Platform Status**: ‚úÖ Production Ready  
**Research Applications**: Academic and industrial cybersecurity research  
**Model Success Rate**: 90-95% across different architectures  
**Dataset Coverage**: 50 APT simulations + 3 large-scale cybersecurity datasets